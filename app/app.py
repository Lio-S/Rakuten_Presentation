import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import os
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import main 

# Configuration de la page
st.set_page_config(
    page_title="Challenge Rakuten - Classification Multimodale",
    page_icon="üõçÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Cache pour le pipeline
@st.cache_resource
def load_pipeline():
    """Charge le pipeline et les mod√®les (mis en cache)"""
    try:
        from preprocess import ProductClassificationPipeline, PipelineConfig
        
        config = PipelineConfig.from_yaml('config.yaml')
        pipeline = ProductClassificationPipeline(config)
        
        # Charger les donn√©es pr√©-trait√©es
        pipeline.prepare_data(force_preprocess_image=False, force_preprocess_text=False)
        
        # Charger les mod√®les pr√©-entra√Æn√©s
        models_loaded = []
        
        try:
            pipeline.load_model('xgboost')
            models_loaded.append("XGBoost")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è XGBoost non disponible: {e}")
        
        try:
            pipeline.load_model('neural_net')
            models_loaded.append("Neural Network")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Neural Net non disponible: {e}")
        
        try:
            pipeline.load_text_model('SVM')
            models_loaded.append("SVM Texte")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è SVM Texte non disponible: {e}")
        
        if not models_loaded:
            st.error("‚ùå Aucun mod√®le n'a pu √™tre charg√©. V√©rifiez que main.py a √©t√© ex√©cut√©.")
            return None
        
        return pipeline
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement du pipeline: {e}")
        st.info("üí° Assurez-vous d'avoir ex√©cut√© main.py pour g√©n√©rer les mod√®les et donn√©es.")
        return None

# Cache pour les donn√©es de r√©sultats
@st.cache_data
def load_results_data():
    """Charge les donn√©es de r√©sultats et rapports"""
    results = {}
    
    # R√©sultats de comparaison des mod√®les
    results_files = {
        'image_models': 'data/results/image_models_comparison_results.csv',
        'text_model': 'data/results/text_model_results.csv',
        'multimodal': 'data/reports/multimodal_comparison_results.csv'
    }
    
    for key, file_path in results_files.items():
        if os.path.exists(file_path):
            try:
                results[key] = pd.read_csv(file_path, index_col=0)
            except Exception as e:
                st.warning(f"Erreur lecture {file_path}: {e}")
    
    # Rapports d√©taill√©s
    rapport_files = {
        'rapport_xgboost': 'data/rapports/rapport_xgboost.csv',
        'rapport_neural_net': 'data/rapports/rapport_neural_net.csv',
        'rapport_text_SVM': 'data/rapports/rapport_text_SVM.csv',
        'erreurs_xgboost': 'data/erreurs/erreurs_xgboost.csv',
        'erreurs_neural_net': 'data/erreurs/erreurs_neural_net.csv',
        'erreurs_text_SVM': 'data/erreurs/erreurs_text_SVM.csv'
    }
    
    for key, file_path in rapport_files.items():
        if os.path.exists(file_path):
            try:
                results[key] = pd.read_csv(file_path)
            except Exception as e:
                st.warning(f"Erreur lecture {file_path}: {e}")
    
    return results

def check_columns_and_get_mapping(df, expected_columns, file_type="rapport"):
    """
    V√©rifie les colonnes disponibles et retourne un mapping avec cr√©ation de colonnes manquantes
    
    Args:
        df: DataFrame √† analyser
        expected_columns: Liste des colonnes attendues
        file_type: Type de fichier ("rapport" ou "erreurs")
    """
    available_columns = df.columns.tolist()
    column_mapping = {}
    
    # Mapping bas√© sur les vraies colonnes g√©n√©r√©es par main.py
    if file_type == "rapport":
        possible_mappings = {
            'true_class_name': ['true_class_name', 'true_category_name', 'true_label'],
            'predicted_class_name': ['predicted_class_name', 'predicted_category_name', 'predicted_label'],
            'correct': ['correct', 'is_correct'],
            'confidence': ['prediction_probability', 'confidence', 'prob_max', 'max_proba'],  # prediction_probability en premier
            'true_category': ['true_category', 'true_label'],
            'predicted_category': ['predicted_category', 'predicted_label']
        }
    else:  # file_type == "erreurs"
        possible_mappings = {
            'true_class_name': ['true_class_name', 'true_category_name', 'true_label'],
            'predicted_class_name': ['predicted_class_name', 'predicted_category_name', 'predicted_label'],
            'correct': ['correct', 'is_correct'],
            'confidence': ['prediction_probability', 'confidence', 'prob_max', 'max_proba'],  # prediction_probability en premier
            'true_category': ['true_category', 'true_label'],
            'predicted_category': ['predicted_category', 'predicted_label']
        }
    
    # Cr√©er une copie du DataFrame pour ajouter les colonnes manquantes
    df_processed = df.copy()
    
    # Mapping des codes vers les noms (bas√© sur votre preprocess.py)
    category_names = {
        10: "Livres", 2280: "Jeux vid√©o", 50: "Jouets & Jeux",
        1280: "Accessoires t√©l√©phones", 2705: "Accessoires console",
        2522: "√âquipement b√©b√©", 2582: "Mat√©riel & accessoires",
        1560: "Photos", 1281: "T√©l√©phonie fixe",
        1920: "Musique amplifi√©e", 2403: "Livres en langues √©trang√®res",
        1140: "TV", 2583: "Articles sport", 1180: "D√©coration",
        1300: "Jeux vid√©o ancien", 2462: "Fournitures bureau",
        1160: "√âlectrom√©nager", 2060: "Articles soins",
        40: "DVD & Films", 60: "Consoles", 1320: "CD",
        1302: "Jeux vid√©o r√©tro", 2220: "Pu√©riculture",
        2905: "Instruments musique", 2585: "Sports & Loisirs",
        1940: "Instrument musique", 1301: "Consoles r√©tro"
    }
    
    # Mapping d√©taill√© avec descriptions et emoji
    def get_category_description(code):
        descriptions = {
            10: {"name": "Livres", "emoji": "üìö", "desc": "Romans, essais, BD, magazines"},
            40: {"name": "DVD & Films", "emoji": "üé¨", "desc": "Films, s√©ries, documentaires"},
            50: {"name": "Jouets & Jeux", "emoji": "üß∏", "desc": "Jouets enfants, jeux de soci√©t√©"},
            60: {"name": "Consoles", "emoji": "üéÆ", "desc": "PlayStation, Xbox, Nintendo"},
            1140: {"name": "TV", "emoji": "üì∫", "desc": "T√©l√©visions, √©crans, projecteurs"},
            1160: {"name": "√âlectrom√©nager", "emoji": "üè†", "desc": "Frigo, lave-linge, micro-ondes"},
            1180: {"name": "D√©coration", "emoji": "üñºÔ∏è", "desc": "Meubles, luminaires, objets d√©co"},
            1280: {"name": "Accessoires t√©l√©phones", "emoji": "üì±", "desc": "Coques, chargeurs, √©couteurs"},
            1281: {"name": "T√©l√©phonie fixe", "emoji": "‚òéÔ∏è", "desc": "T√©l√©phones fixes, r√©pondeurs"},
            1300: {"name": "Jeux vid√©o ancien", "emoji": "üïπÔ∏è", "desc": "Jeux r√©tro, collectors"},
            1301: {"name": "Consoles r√©tro", "emoji": "üëæ", "desc": "Anciennes consoles de jeu"},
            1302: {"name": "Jeux vid√©o r√©tro", "emoji": "üéØ", "desc": "Jeux vintage, cartouches"},
            1320: {"name": "CD", "emoji": "üíø", "desc": "Musique, albums, compilations"},
            1560: {"name": "Photos", "emoji": "üì∑", "desc": "Appareils photo, objectifs"},
            1920: {"name": "Musique amplifi√©e", "emoji": "üéµ", "desc": "Enceintes, amplis, sono"},
            1940: {"name": "Instrument musique", "emoji": "üé∏", "desc": "Guitares, pianos, batteries"},
            2060: {"name": "Articles soins", "emoji": "üß¥", "desc": "Cosm√©tiques, hygi√®ne, bien-√™tre"},
            2220: {"name": "Pu√©riculture", "emoji": "üë∂", "desc": "Poussettes, biberons, v√™tements b√©b√©"},
            2280: {"name": "Jeux vid√©o", "emoji": "üéÆ", "desc": "Jeux r√©cents, derni√®res sorties"},
            2403: {"name": "Livres en langues √©trang√®res", "emoji": "üìñ", "desc": "Livres anglais, multilingues"},
            2462: {"name": "Fournitures bureau", "emoji": "‚úèÔ∏è", "desc": "Stylos, cahiers, classeurs"},
            2522: {"name": "√âquipement b√©b√©", "emoji": "üçº", "desc": "Mobilier, s√©curit√©, √©veil b√©b√©"},
            2582: {"name": "Mat√©riel & accessoires", "emoji": "üîß", "desc": "Outils, bricolage, jardinage"},
            2583: {"name": "Articles sport", "emoji": "‚öΩ", "desc": "√âquipement sportif, v√™tements"},
            2585: {"name": "Sports & Loisirs", "emoji": "üèÉ", "desc": "Fitness, outdoor, loisirs cr√©atifs"},
            2705: {"name": "Accessoires console", "emoji": "üéÆ", "desc": "Manettes, casques gaming"},
            2905: {"name": "Instruments musique", "emoji": "üé∫", "desc": "Instruments √† vent, cordes, percussions"}
        }
        
        return descriptions.get(code, {
            "name": f"Code_{code}", 
            "emoji": "‚ùì", 
            "desc": "Cat√©gorie non document√©e"
        })
    
    # Fonction pour am√©liorer la s√©lection d'exemples
    def get_diverse_examples():
        """S√©lectionne des exemples en s'assurant d'avoir une bonne diversit√© de cat√©gories"""
        try:
            # Charger les donn√©es
            X_train_df = pd.read_csv('data/X_train_update.csv', index_col=0)
            Y_train_df = pd.read_csv('data/Y_train_CVw08PX.csv', index_col=0)
            
            # R√©cup√©rer les indices du test_split
            if hasattr(pipeline, 'preprocessed_data') and 'test_split_indices' in pipeline.preprocessed_data:
                test_split_indices = pipeline.preprocessed_data['test_split_indices']
            else:
                n_total = len(X_train_df)
                test_split_indices = X_train_df.index[-int(0.2 * n_total):]
            
            # Grouper par cat√©gorie
            available_indices = [idx for idx in test_split_indices if idx in X_train_df.index and idx in Y_train_df.index]
            
            category_groups = {}
            for idx in available_indices:
                if idx in Y_train_df.index:
                    category = Y_train_df.loc[idx, 'prdtypecode']
                    if category not in category_groups:
                        category_groups[category] = []
                    category_groups[category].append(idx)
            
            # S√©lectionner 2-3 exemples par cat√©gorie disponible
            selected_examples = []
            
            for category, indices in category_groups.items():
                # V√©rifier que les images existent
                valid_indices = []
                for idx in indices[:10]:  # V√©rifier les 10 premiers
                    row = X_train_df.loc[idx]
                    image_file = f"image_{row['imageid']}_product_{row['productid']}.jpg"
                    image_path = os.path.join('data/images/image_train', image_file)
                    if os.path.exists(image_path):
                        valid_indices.append(idx)
                
                # Prendre 2-3 exemples valides par cat√©gorie
                if len(valid_indices) > 0:
                    n_samples = min(3, len(valid_indices))
                    selected_indices = np.random.choice(valid_indices, size=n_samples, replace=False)
                    selected_examples.extend(selected_indices)
            
            # Cr√©er les exemples
            samples = []
            for idx in selected_examples:
                row = X_train_df.loc[idx]
                label = Y_train_df.loc[idx]
                
                designation = str(row.get('designation', '')).strip()
                description = str(row.get('description', '')).strip()
                text = f"{designation} {description}".strip()
                
                image_file = f"image_{row['imageid']}_product_{row['productid']}.jpg"
                image_path = os.path.join('data/images/image_train', image_file)
                
                class_code = label['prdtypecode']
                category_info = get_category_description(class_code)
                
                if len(text) > 20:
                    samples.append({
                        'text': text,
                        'image_path': image_path,
                        'class_name': category_info['name'],
                        'class_code': class_code,
                        'class_emoji': category_info['emoji'],
                        'class_desc': category_info['desc'],
                        'imageid': row['imageid'],
                        'productid': row['productid'],
                        'index': idx,
                        'designation': designation,
                        'description': description
                    })
            
            return samples, category_groups
            
        except Exception as e:
            st.error(f"‚ùå Erreur s√©lection exemples diversifi√©s: {e}")
            return [], {}
    
    for expected_col in expected_columns:
        # Chercher la colonne existante
        found = False
        for possible_name in possible_mappings.get(expected_col, [expected_col]):
            if possible_name in available_columns:
                column_mapping[expected_col] = possible_name
                found = True
                break
        
        # Si pas trouv√©e, essayer de cr√©er la colonne
        if not found:
            if expected_col == 'correct' and 'true_category' in available_columns and 'predicted_category' in available_columns:
                # Cr√©er la colonne 'correct' en comparant true_category et predicted_category
                df_processed['correct'] = df_processed['true_category'] == df_processed['predicted_category']
                column_mapping['correct'] = 'correct'
                st.info("‚úÖ Colonne 'correct' cr√©√©e automatiquement")
                found = True
                
            elif expected_col == 'confidence':
                # V√©rifier d'abord si prediction_probability existe
                if 'prediction_probability' in available_columns:
                    column_mapping['confidence'] = 'prediction_probability'
                    found = True
                elif file_type == "erreurs":
                    # Pour les fichiers d'erreurs, la confidence peut ne pas exister
                    st.info("‚ÑπÔ∏è Colonne 'confidence' non disponible dans le fichier d'erreurs")
                    # Ne pas cr√©er de colonne par d√©faut, juste ignorer
                    found = False
                else:
                    # Pour les rapports, essayer autres noms
                    found = False
                
            elif expected_col == 'true_class_name':
                # Essayer de cr√©er √† partir de true_category_name ou true_category
                if 'true_category_name' in available_columns:
                    column_mapping['true_class_name'] = 'true_category_name'
                    found = True
                elif 'true_category' in available_columns:
                    df_processed['true_class_name'] = df_processed['true_category'].map(category_names)
                    column_mapping['true_class_name'] = 'true_class_name'
                    st.info("‚úÖ Colonne 'true_class_name' cr√©√©e √† partir de 'true_category'")
                    found = True
                    
            elif expected_col == 'predicted_class_name':
                # Essayer de cr√©er √† partir de predicted_category_name ou predicted_category
                if 'predicted_category_name' in available_columns:
                    column_mapping['predicted_class_name'] = 'predicted_category_name'
                    found = True
                elif 'predicted_category' in available_columns:
                    df_processed['predicted_class_name'] = df_processed['predicted_category'].map(category_names)
                    column_mapping['predicted_class_name'] = 'predicted_class_name'
                    st.info("‚úÖ Colonne 'predicted_class_name' cr√©√©e √† partir de 'predicted_category'")
                    found = True
        
        # Si toujours pas trouv√©e, warning seulement si c'est critique
        if not found and expected_col != 'confidence':
            st.warning(f"‚ö†Ô∏è Colonne '{expected_col}' non trouv√©e. Colonnes disponibles: {available_columns}")
    
    return column_mapping, df_processed

# Sidebar pour navigation
st.sidebar.title("üõçÔ∏è Navigation")
page = st.sidebar.selectbox(
    "Choisir une page",
    ["üè† Accueil", "üìä R√©sultats Globaux", "üñºÔ∏è Analyse Images", "üìù Analyse Texte", 
     "üîó Analyse Multimodale", "üß™ Test Nouvelles Donn√©es", "üéØ Explicabilit√©"]
)

# Charger le pipeline
pipeline = load_pipeline()
results_data = load_results_data()

# V√©rification que le pipeline est disponible
if pipeline is None:
    st.error("‚ùå Pipeline non disponible")
    st.info("üí° Veuillez ex√©cuter main.py pour g√©n√©rer les mod√®les et donn√©es avant d'utiliser cette application.")
    st.stop()  # Arr√™te l'ex√©cution de l'app

# ==================== PAGE ACCUEIL ====================
if page == "üè† Accueil":
    st.title("üõçÔ∏è Challenge Rakuten - Classification Multimodale")
    st.markdown("---")
    
    # Pr√©sentation du projet
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ## üéØ Objectif du Challenge
        
        Ce projet vise √† **classifier automatiquement les produits Rakuten** en utilisant :
        - üìù **Texte** (designation + description)
        - üñºÔ∏è **Images** des produits
        - üîó **Fusion multimodale** des deux approches
        
        ### üìä Donn√©es du Challenge
        """)
        
        # Statistiques g√©n√©rales
        stats_col1, stats_col2, stats_col3 = st.columns(3)
        with stats_col1:
            st.metric("üì¶ Produits Total", "84,916")
            st.metric("üèãÔ∏è Train Balanc√©", "54,000")
        with stats_col2:
            st.metric("üéØ Classes", "27")
            st.metric("üß™ Test Split", "16,984")
        with stats_col3:
            st.metric("üñºÔ∏è Images", "84,916")
            st.metric("üìù Textes", "84,916")
    
    with col2:
        st.markdown("""
        ### üèÜ Meilleurs R√©sultats
        """)
        
        # Afficher les meilleurs r√©sultats si disponibles
        if 'multimodal' in results_data and not results_data['multimodal'].empty:
            try:
                best_model = results_data['multimodal'].loc[results_data['multimodal']['weighted_f1'].idxmax()]
                st.success(f"ü•á **{best_model.name}**")
                st.metric("F1-Score", f"{best_model['weighted_f1']:.3f}")
                st.metric("Accuracy", f"{best_model['accuracy']:.3f}")
            except Exception as e:
                st.info("R√©sultats multimodaux en cours de traitement...")
        else:
            st.info("R√©sultats multimodaux en cours de traitement...")
    
    # Distribution des classes
    st.markdown("### üìä Distribution des Classes")
    
    # Donn√©es de distribution (bas√©es sur vos outputs)
    class_data = {
        'Classe': [10, 40, 50, 60, 1140, 1160, 1180, 1280, 1281, 1300, 1301, 1302, 1320, 1560, 1920, 1940, 2060, 2220, 2280, 2403, 2462, 2522, 2582, 2583, 2585, 2705, 2905],
        'Nom': ['Livres', 'DVD & Films', 'Jouets & Jeux', 'Consoles', 'TV', '√âlectrom√©nager', 'D√©coration', 'Accessoires t√©l√©phones', 'T√©l√©phonie fixe', 'Jeux vid√©o ancien', 'Consoles r√©tro', 'Jeux vid√©o r√©tro', 'CD', 'Photos', 'Musique amplifi√©e', 'Instrument musique', 'Articles soins', 'Pu√©riculture', 'Jeux vid√©o', 'Livres en langues √©trang√®res', 'Fournitures bureau', '√âquipement b√©b√©', 'Mat√©riel & accessoires', 'Articles sport', 'Sports & Loisirs', 'Accessoires console', 'Instruments musique'],
        '√âchantillons': [3116, 2508, 1681, 832, 2671, 3953, 764, 4870, 2070, 5045, 807, 2491, 3241, 5073, 4303, 803, 4993, 824, 4760, 4774, 1421, 4989, 2589, 10209, 2496, 2761, 872],
        'Pourcentage': [3.67, 2.95, 1.98, 0.98, 3.15, 4.66, 0.90, 5.74, 2.44, 5.94, 0.95, 2.93, 3.82, 5.97, 5.07, 0.95, 5.88, 0.97, 5.61, 5.62, 1.67, 5.88, 3.05, 12.02, 2.94, 3.25, 1.03]
    }
    
    df_classes = pd.DataFrame(class_data)
    
    # Graphique interactif
    fig = px.bar(df_classes, x='Nom', y='√âchantillons', 
                 title="Distribution des Classes (Donn√©es Originales)",
                 labels={'Nom': 'Cat√©gorie', '√âchantillons': 'Nombre d\'√©chantillons'})
    fig.update_xaxes(tickangle=45)
    st.plotly_chart(fig, use_container_width=True)

# ==================== PAGE R√âSULTATS GLOBAUX ====================
elif page == "üìä R√©sultats Globaux":
    st.title("üìä R√©sultats Globaux de Classification")
    st.markdown("---")
    
    # Comparaison des mod√®les
    if 'image_models' in results_data and 'text_model' in results_data:
        st.subheader("üèÜ Comparaison des Performances")
        
        # Pr√©parer les donn√©es pour la comparaison
        comparison_data = []
        
        # Mod√®les image
        for model_name, row in results_data['image_models'].iterrows():
            comparison_data.append({
                'Mod√®le': model_name,
                'Type': 'Image',
                'Accuracy': row['accuracy'],
                'F1-Score': row['weighted_f1'],
                'Pr√©cision': row.get('weighted_precision', 0),
                'Rappel': row.get('weighted_recall', 0)
            })
        
        # Mod√®le texte
        for model_name, row in results_data['text_model'].iterrows():
            comparison_data.append({
                'Mod√®le': model_name,
                'Type': 'Texte',
                'Accuracy': row['accuracy'],
                'F1-Score': row['weighted_f1'],
                'Pr√©cision': row.get('weighted_precision', 0),
                'Rappel': row.get('weighted_recall', 0)
            })
        
        # Mod√®les multimodaux
        if 'multimodal' in results_data and not results_data['multimodal'].empty:
            for model_name, row in results_data['multimodal'].iterrows():
                model_type = 'Multimodal' if 'multimodal' in str(row.get('model_type', '')) else 'Fusion'
                comparison_data.append({
                    'Mod√®le': model_name,
                    'Type': model_type,
                    'Accuracy': row['accuracy'],
                    'F1-Score': row['weighted_f1'],
                    'Pr√©cision': row.get('weighted_precision', 0),
                    'Rappel': row.get('weighted_recall', 0)
                })
        
        df_comparison = pd.DataFrame(comparison_data)
        
        if not df_comparison.empty:
            # Graphique de comparaison
            fig = px.scatter(df_comparison, x='Accuracy', y='F1-Score', 
                            color='Type', size='Pr√©cision',
                            hover_data=['Mod√®le', 'Rappel'],
                            title="Performance des Mod√®les (Accuracy vs F1-Score)")
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau r√©capitulatif
            st.subheader("üìã Tableau R√©capitulatif")
            df_display = df_comparison.round(3)
            st.dataframe(df_display, use_container_width=True)
    
    # M√©triques par classe (si disponible)
    if 'rapport_xgboost' in results_data:
        st.subheader("üìä Performance par Classe")
        
        rapport = results_data['rapport_xgboost']
        
        # V√©rifier les colonnes disponibles
        column_mapping, rapport_processed = check_columns_and_get_mapping(rapport, ['true_class_name', 'correct', 'confidence'], "rapport")
        
        if 'true_class_name' in column_mapping and 'correct' in column_mapping:
            # Calculer les m√©triques par classe
            try:
                # Utiliser le DataFrame trait√©
                true_col = column_mapping['true_class_name']
                correct_col = column_mapping['correct']
                conf_col = column_mapping.get('confidence', correct_col)
                
                class_metrics = rapport_processed.groupby(true_col).agg({
                    correct_col: 'mean',
                    conf_col: 'mean'
                }).round(3)
                
                class_metrics.columns = ['Accuracy', 'Confiance Moyenne']
                
                # Trier par accuracy
                class_metrics = class_metrics.sort_values('Accuracy', ascending=False)
                
                st.dataframe(class_metrics, use_container_width=True)
            except Exception as e:
                st.error(f"Erreur calcul m√©triques par classe: {e}")
                st.info("Colonnes disponibles: " + str(rapport.columns.tolist()))

# ==================== PAGE ANALYSE IMAGES ====================
elif page == "üñºÔ∏è Analyse Images":
    st.title("üñºÔ∏è Analyse des Mod√®les Image")
    st.markdown("---")
    
    # S√©lection du mod√®le
    model_choice = st.selectbox("Choisir le mod√®le image", ["xgboost", "neural_net"])
    
    if f'rapport_{model_choice}' in results_data:
        rapport = results_data[f'rapport_{model_choice}']
        
        # V√©rifier les colonnes disponibles
        column_mapping, rapport_processed = check_columns_and_get_mapping(rapport, ['correct', 'confidence', 'true_class_name', 'predicted_class_name'], "rapport")
        
        if 'correct' in column_mapping and 'confidence' in column_mapping:
            # M√©triques globales
            st.subheader("üìä M√©triques Globales")
            col1, col2, col3, col4 = st.columns(4)
            
            correct_col = column_mapping['correct']
            conf_col = column_mapping['confidence']
            
            with col1:
                accuracy = rapport_processed[correct_col].mean()
                st.metric("Accuracy", f"{accuracy:.3f}")
            
            with col2:
                confidence = rapport_processed[conf_col].mean()
                st.metric("Confiance Moyenne", f"{confidence:.3f}")
            
            with col3:
                high_conf = (rapport_processed[conf_col] > 0.8).sum()
                st.metric("Haute Confiance (>0.8)", f"{high_conf}")
            
            with col4:
                low_conf = (rapport_processed[conf_col] < 0.5).sum()
                st.metric("Faible Confiance (<0.5)", f"{low_conf}")
            
            # Distribution des confiances
            st.subheader("üìà Distribution des Confiances")
            fig = px.histogram(rapport_processed, x=conf_col, nbins=50,
                              title="Distribution des Scores de Confiance")
            st.plotly_chart(fig, use_container_width=True)
            
            # Matrice de confusion (top 10 classes)
            if 'true_class_name' in column_mapping and 'predicted_class_name' in column_mapping:
                st.subheader("üéØ Matrice de Confusion (Top 10 Classes)")
                
                true_col = column_mapping['true_class_name']
                pred_col = column_mapping['predicted_class_name']
                
                # Prendre les 10 classes les plus fr√©quentes
                top_classes = rapport_processed[true_col].value_counts().head(10).index
                rapport_top = rapport_processed[rapport_processed[true_col].isin(top_classes)]
                
                if not rapport_top.empty:
                    confusion_matrix = pd.crosstab(rapport_top[true_col], 
                                                 rapport_top[pred_col])
                    
                    fig = px.imshow(confusion_matrix, text_auto=True,
                                   title="Matrice de Confusion (Top 10 Classes)")
                    st.plotly_chart(fig, use_container_width=True)
        
        # Analyse des erreurs
        if f'erreurs_{model_choice}' in results_data:
            st.subheader("‚ùå Analyse des Erreurs")
            erreurs = results_data[f'erreurs_{model_choice}']
            
            # V√©rifier les colonnes des erreurs
            error_column_mapping, erreurs_processed = check_columns_and_get_mapping(erreurs, ['true_class_name', 'predicted_class_name', 'confidence'], "erreurs")
            
            if 'true_class_name' in error_column_mapping:
                true_col = error_column_mapping['true_class_name']
                
                # Erreurs par classe
                erreurs_par_classe = erreurs_processed.groupby(true_col).size().sort_values(ascending=False)
                
                fig = px.bar(x=erreurs_par_classe.index[:15], y=erreurs_par_classe.values[:15],
                            title="Nombre d'Erreurs par Classe (Top 15)")
                st.plotly_chart(fig, use_container_width=True)
                
                # Exemples d'erreurs
                st.subheader("üîç Exemples d'Erreurs")
                sample_errors = erreurs_processed.sample(min(10, len(erreurs_processed)))
                
                for _, error in sample_errors.iterrows():
                    true_name = error.get(error_column_mapping.get('true_class_name', 'N/A'), 'N/A')
                    pred_name = error.get(error_column_mapping.get('predicted_class_name', 'N/A'), 'N/A')
                    
                    with st.expander(f"Erreur: {true_name} ‚Üí {pred_name}"):
                        # Afficher la confiance seulement si elle existe
                        if 'confidence' in error_column_mapping:
                            conf_val = error.get(error_column_mapping['confidence'], 'N/A')
                            st.write(f"**Probabilit√© de pr√©diction**: {conf_val}")
                        elif 'prediction_probability' in error.columns:
                            conf_val = error.get('prediction_probability', 'N/A')
                            st.write(f"**Probabilit√© de pr√©diction**: {conf_val}")
                        else:
                            st.write("**Probabilit√© de pr√©diction**: Non disponible")
                        
                        if 'error_type' in error:
                            st.write(f"**Type d'erreur**: {error.get('error_type', 'N/A')}")
                        
                        # Afficher des infos additionnelles disponibles
                        if 'imageid' in error:
                            st.write(f"**ID Image**: {error.get('imageid', 'N/A')}")
                        if 'original_index' in error:
                            st.write(f"**Index Original**: {error.get('original_index', 'N/A')}")
    else:
        st.warning(f"Rapport pour {model_choice} non disponible. Ex√©cutez d'abord main.py pour g√©n√©rer les rapports.")

# ==================== PAGE ANALYSE TEXTE ====================
elif page == "üìù Analyse Texte":
    st.title("üìù Analyse du Mod√®le Texte (SVM)")
    st.markdown("---")
    
    if 'rapport_text_SVM' in results_data:
        rapport = results_data['rapport_text_SVM']
        
        # V√©rifier les colonnes disponibles
        column_mapping, rapport_processed = check_columns_and_get_mapping(rapport, ['correct', 'confidence', 'text_sample'], "rapport")
        
        if 'correct' in column_mapping and 'confidence' in column_mapping:
            correct_col = column_mapping['correct']
            conf_col = column_mapping['confidence']
            
            # M√©triques globales
            st.subheader("üìä M√©triques Globales")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                accuracy = rapport_processed[correct_col].mean()
                st.metric("Accuracy", f"{accuracy:.3f}")
            
            with col2:
                confidence = rapport_processed[conf_col].mean()
                st.metric("Confiance Moyenne", f"{confidence:.3f}")
            
            with col3:
                high_conf = (rapport_processed[conf_col] > 0.8).sum()
                st.metric("Haute Confiance", f"{high_conf}")
            
            with col4:
                low_conf = (rapport_processed[conf_col] < 0.5).sum()
                st.metric("Faible Confiance", f"{low_conf}")
            
            # Analyse des textes
            st.subheader("üìù Analyse des Textes")
            
            # Longueur des textes
            if 'text_sample' in column_mapping:
                text_col = column_mapping['text_sample']
                rapport_processed['text_length'] = rapport_processed[text_col].str.len()
                
                fig = px.histogram(rapport_processed, x='text_length', nbins=50,
                                  title="Distribution des Longueurs de Texte")
                st.plotly_chart(fig, use_container_width=True)
                
                # Corr√©lation longueur vs confiance
                fig = px.scatter(rapport_processed, x='text_length', y=conf_col,
                                color=correct_col, title="Longueur du Texte vs Confiance")
                st.plotly_chart(fig, use_container_width=True)
            
            # Mots les plus fr√©quents dans les erreurs
            if 'erreurs_text_SVM' in results_data:
                st.subheader("üîç Analyse des Erreurs Texte")
                erreurs = results_data['erreurs_text_SVM']
                
                # V√©rifier les colonnes des erreurs
                error_column_mapping, erreurs_processed = check_columns_and_get_mapping(erreurs, ['true_class_name', 'predicted_class_name', 'confidence', 'text_sample'], "erreurs")
                
                # Quelques exemples d'erreurs
                st.write("**Exemples d'erreurs de classification :**")
                sample_errors = erreurs_processed.sample(min(5, len(erreurs_processed)))
                
                for _, error in sample_errors.iterrows():
                    true_class = error.get(error_column_mapping.get('true_class_name', 'N/A'), 'N/A')
                    pred_class = error.get(error_column_mapping.get('predicted_class_name', 'N/A'), 'N/A')
                    
                    with st.expander(f"Erreur: {true_class} ‚Üí {pred_class}"):
                        # Afficher la confiance seulement si elle existe
                        if 'confidence' in error_column_mapping:
                            conf_val = error.get(error_column_mapping['confidence'], 'N/A')
                            st.write(f"**Confiance**: {conf_val}")
                        else:
                            st.write("**Confiance**: Non disponible")
                        
                        if 'text_sample' in error_column_mapping:
                            text_sample = error.get(error_column_mapping['text_sample'], 'N/A')
                            st.write(f"**Texte**: {str(text_sample)[:200]}...")
    else:
        st.warning("Rapport texte SVM non disponible. Ex√©cutez d'abord main.py pour g√©n√©rer les rapports.")

# ==================== PAGE ANALYSE MULTIMODALE ====================
elif page == "üîó Analyse Multimodale":
    st.title("üîó Analyse Multimodale")
    st.markdown("---")
    
    if 'multimodal' in results_data and not results_data['multimodal'].empty:
        multimodal_results = results_data['multimodal']
        
        # Comparaison des strat√©gies de fusion
        st.subheader("üîÄ Comparaison des Strat√©gies de Fusion")
        
        # Filtrer les r√©sultats multimodaux
        fusion_results = multimodal_results[multimodal_results['model_type'] == 'multimodal']
        
        if not fusion_results.empty:
            # Graphique de comparaison
            fig = px.bar(fusion_results, x=fusion_results.index, y='weighted_f1',
                        title="Performance des Strat√©gies de Fusion")
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau d√©taill√©
            st.dataframe(fusion_results[['accuracy', 'weighted_f1']].round(3), use_container_width=True)
        
        # Analyse de l'am√©lioration multimodale
        st.subheader("üìà Gain de la Fusion Multimodale")
        
        # Comparer avec les mod√®les individuels
        individual_results = multimodal_results[multimodal_results['model_type'] != 'multimodal']
        
        if not individual_results.empty:
            comparison_fig = px.bar(
                x=multimodal_results.index,
                y=multimodal_results['weighted_f1'],
                color=multimodal_results['model_type'],
                title="Comparaison Individuel vs Multimodal"
            )
            st.plotly_chart(comparison_fig, use_container_width=True)
    else:
        st.warning("R√©sultats multimodaux non disponibles. Ex√©cutez d'abord main.py pour g√©n√©rer les analyses multimodales.")

# ==================== PAGE TEST NOUVELLES DONN√âES ====================
elif page == "üß™ Test Nouvelles Donn√©es":
    st.title("üß™ Test sur Nouvelles Donn√©es")
    st.markdown("---")
    
    # Explication des modes
    with st.expander("üìñ Explication des modes de test"):
        st.markdown("""
        **üé≤ Exemple test_split**: Utilise des donn√©es **non vues pendant l'entra√Ænement** (20% des donn√©es d'origine). 
        Les labels sont connus, permettant une √©valuation correcte des performances.
        
        **üèÜ Exemple challenge**: Utilise les **vraies donn√©es de test du challenge**. 
        Les labels ne sont pas connus, simule une utilisation r√©elle.
        
        **‚úçÔ∏è Saisie manuelle**: Permet de tester avec vos propres donn√©es.
        
        **üìÅ Upload fichier**: Traite des fichiers CSV avec plusieurs exemples.
        """)
    
    st.markdown("---")
    
    # S√©lection des param√®tres
    st.subheader("‚öôÔ∏è Configuration")
    col1, col2 = st.columns(2)
    
    with col1:
        model_type = st.selectbox("Mod√®le Image", ["xgboost", "neural_net"])
    
    with col2:
        fusion_strategy = st.selectbox("Strat√©gie de Fusion", 
                                      ["mean", "product", "weighted", "confidence_weighted"])
    
    # Interface de test
    st.subheader("üìù Saisie des Donn√©es")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Texte du produit:**")
        text_input = st.text_area("Description + D√©signation", 
                                 value="Smartphone Samsung Galaxy derni√®re g√©n√©ration avec √©cran OLED",
                                 height=100)
    
    with col2:
        st.write("**Image du produit:**")
        uploaded_file = st.file_uploader("Choisir une image...", type=["jpg", "jpeg", "png"])
        
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.image(image, caption="Image t√©l√©charg√©e", use_container_width=True)
            
            # Sauvegarder temporairement
            temp_dir = "temp_uploads"
            os.makedirs(temp_dir, exist_ok=True)
            temp_image_path = os.path.join(temp_dir, uploaded_file.name)
            image.save(temp_image_path)
        else:
            temp_image_path = None
    
    # Bouton de pr√©diction
    if st.button("üîç Classifier le Produit", disabled=(temp_image_path is None)):
        try:
            with st.spinner("Classification en cours..."):
                # Charger le mod√®le s√©lectionn√©
                pipeline.load_model(model_type)
                
                # S'assurer que le texte est bien une cha√Æne de caract√®res
                text_input_clean = str(text_input).strip()
                
                # Effectuer la pr√©diction
                results = pipeline.predict_multimodal(text_input_clean, temp_image_path, fusion_strategy)
                
                # Afficher les r√©sultats
                st.success("‚úÖ Classification termin√©e!")
                
                # R√©sultat principal
                st.subheader("üéØ R√©sultat Principal")
                st.success(f"**Classe pr√©dite:** {results['predicted_class_name']}")
                st.info(f"**Code classe:** {results['predicted_class']}")
                
                # Probabilit√©s top 5
                st.subheader("üìä Top 5 des Probabilit√©s")
                top_indices = np.argsort(results['probabilities'])[-5:][::-1]
                top_probs = results['probabilities'][top_indices]
                top_classes = [pipeline.category_names[pipeline.idx_to_category[idx]] for idx in top_indices]
                
                prob_df = pd.DataFrame({
                    "Classe": top_classes,
                    "Probabilit√©": top_probs
                })
                
                # Graphique des probabilit√©s
                fig = px.bar(prob_df, x="Probabilit√©", y="Classe", orientation='h',
                            title="Top 5 des Pr√©dictions")
                st.plotly_chart(fig, use_container_width=True)
                
                # Comparaison des modalit√©s
                st.subheader("üîÑ Comparaison par Modalit√©")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Texte seul", 
                             pipeline.category_names[results['text_prediction']])
                
                with col2:
                    st.metric("Image seule", 
                             pipeline.category_names[results['image_prediction']])
                
                with col3:
                    st.metric("Fusion", 
                             results['predicted_class_name'])
                
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la classification: {str(e)}")
            st.error("V√©rifiez que tous les mod√®les sont correctement charg√©s.")
            
            # Informations de d√©bogage
            with st.expander("üîç Informations de d√©bogage"):
                st.write(f"**Type de text_input:** {type(text_input)}")
                st.write(f"**Contenu de text_input:** {text_input}")
                st.write(f"**Chemin image:** {temp_image_path}")
                st.write(f"**Mod√®le s√©lectionn√©:** {model_type}")
                st.write(f"**Strat√©gie de fusion:** {fusion_strategy}")

# ==================== PAGE EXPLICABILIT√â ====================
elif page == "üéØ Explicabilit√©":
    st.title("üéØ Explicabilit√© des Mod√®les")
    st.markdown("---")
    
    st.info("üí° Cette section fournit des explications simplifi√©es sur les pr√©dictions multimodales en utilisant les donn√©es test_split.")
    
    # Fonction pour r√©cup√©rer des exemples test_split
    @st.cache_data
    def get_test_split_examples():
        """R√©cup√®re des exemples depuis les donn√©es test_split pour l'explicabilit√©"""
        try:
            # Charger les donn√©es originales
            X_train_df = pd.read_csv('data/X_train_update.csv', index_col=0)
            Y_train_df = pd.read_csv('data/Y_train_CVw08PX.csv', index_col=0)
            
            # R√©cup√©rer les indices du test_split depuis le pipeline
            if hasattr(pipeline, 'preprocessed_data') and 'test_split_indices' in pipeline.preprocessed_data:
                test_split_indices = pipeline.preprocessed_data['test_split_indices']
            else:
                # Fallback
                n_total = len(X_train_df)
                test_split_indices = X_train_df.index[-int(0.2 * n_total):]
                st.warning("‚ö†Ô∏è Indices test_split non trouv√©s, utilisation d'une approximation")
            
            # Prendre quelques exemples pour l'explicabilit√©
            available_indices = [idx for idx in test_split_indices if idx in X_train_df.index and idx in Y_train_df.index]
            sample_indices = np.random.choice(available_indices, size=min(10, len(available_indices)), replace=False)
            
            samples = []
            for idx in sample_indices:
                row = X_train_df.loc[idx]
                label = Y_train_df.loc[idx]
                
                # Construire le texte
                text = f"{row.get('designation', '')} {row.get('description', '')}".strip()
                
                # Construire le chemin image
                image_file = f"image_{row['imageid']}_product_{row['productid']}.jpg"
                image_path = os.path.join('data/images/image_train', image_file)
                
                # Nom de la classe
                class_name = pipeline.category_names.get(label['prdtypecode'], 'Unknown')
                
                if os.path.exists(image_path) and len(text) > 10:
                    samples.append({
                        'text': text,
                        'image_path': image_path,
                        'class_name': class_name,
                        'class_code': label['prdtypecode'],
                        'imageid': row['imageid'],
                        'productid': row['productid'],
                        'index': idx
                    })
            
            return samples
            
        except Exception as e:
            st.error(f"‚ùå Erreur chargement exemples test_split: {e}")
            return []
    
    # Charger les exemples test_split
    test_examples = get_test_split_examples()
    
    # Interface pour charger un exemple
    st.subheader("üìù S√©lection de l'Exemple")
    
    # Choix du mode
    mode = st.radio("Source des donn√©es", 
                   ["üé≤ Exemple test_split", "‚úçÔ∏è Saisie manuelle"])
    
    if mode == "üé≤ Exemple test_split" and test_examples:
        st.info("üìä **Utilisation des donn√©es test_split** (non vues pendant l'entra√Ænement)")
        
        # S√©lectionner un exemple
        if st.button("üé≤ G√©n√©rer un exemple test_split"):
            st.session_state.current_explainer_example = np.random.choice(test_examples)
        
        # Afficher l'exemple actuel
        if 'current_explainer_example' not in st.session_state and test_examples:
            st.session_state.current_explainer_example = test_examples[0]
        
        if 'current_explainer_example' in st.session_state:
            example = st.session_state.current_explainer_example
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Texte du produit:**")
                text_input = st.text_area("Description + D√©signation", 
                                         value=example['text'][:400] + "..." if len(example['text']) > 400 else example['text'],
                                         height=120)
                st.success(f"**Classe r√©elle:** {example['class_name']} ({example['class_code']})")
            
            with col2:
                st.write("**Image du produit:**")
                if os.path.exists(example['image_path']):
                    image = Image.open(example['image_path'])
                    st.image(image, caption=f"Image ID: {example['imageid']}", use_container_width=True)
                    temp_image_path = example['image_path']
                else:
                    st.error("Image non trouv√©e")
                    temp_image_path = None
    
    else:  # Saisie manuelle
        col1, col2 = st.columns(2)
        
        with col1:
            text_input = st.text_area("Texte", "Console de jeu PlayStation 5 derni√®re g√©n√©ration")
        
        with col2:
            uploaded_file = st.file_uploader("Image", type=["jpg", "jpeg", "png"])
            
            if uploaded_file is not None:
                image = Image.open(uploaded_file)
                st.image(image, caption="Image pour analyse", use_container_width=True)
                
                temp_dir = "temp_uploads"
                os.makedirs(temp_dir, exist_ok=True)
                temp_image_path = os.path.join(temp_dir, uploaded_file.name)
                image.save(temp_image_path)
            else:
                temp_image_path = None
    
    fusion_strategy = st.selectbox("Strat√©gie de fusion", ["mean", "product", "weighted", "confidence_weighted"])
    
    if st.button("üîç G√©n√©rer les Explications", disabled=(temp_image_path is None)):
        try:
            with st.spinner("G√©n√©ration des explications..."):
                # S'assurer que le texte est bien une cha√Æne de caract√®res (m√™me correction que pour les tests)
                def clean_text_input(text_input):
                    if isinstance(text_input, np.ndarray):
                        if text_input.size == 1:
                            return str(text_input.item()).strip()
                        else:
                            return ' '.join([str(item) for item in text_input.flatten()]).strip()
                    elif text_input is None:
                        return ""
                    else:
                        return str(text_input).strip()
                
                text_input_clean = clean_text_input(text_input)
                
                if len(text_input_clean) == 0:
                    st.error("‚ùå Le texte d'entr√©e est vide apr√®s nettoyage")
                    st.stop()
                
                explanations = pipeline.get_model_explanations(text_input_clean, temp_image_path, fusion_strategy)
                
                if 'error' in explanations:
                    st.error(f"‚ùå Erreur: {explanations['error']}")
                else:
                    # R√©sultat de la pr√©diction
                    st.subheader("üéØ R√©sultat de la Pr√©diction")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("Classe Pr√©dite", explanations['prediction']['predicted_class_name'])
                    with col2:
                        st.metric("Confiance", f"{explanations['prediction']['confidence']:.3f}")
                    with col3:
                        st.metric("Code Classe", explanations['prediction']['predicted_class'])
                    
                    # Comparaison avec la v√©rit√© terrain pour test_split
                    if mode == "üé≤ Exemple test_split" and 'current_explainer_example' in st.session_state:
                        example = st.session_state.current_explainer_example
                        is_correct = explanations['prediction']['predicted_class'] == example['class_code']
                        
                        st.subheader("üéØ √âvaluation vs V√©rit√© Terrain")
                        eval_col1, eval_col2, eval_col3 = st.columns(3)
                        
                        with eval_col1:
                            status = "‚úÖ Correct" if is_correct else "‚ùå Incorrect"
                            st.metric("R√©sultat", status)
                        with eval_col2:
                            st.metric("Classe R√©elle", example['class_name'])
                        with eval_col3:
                            st.metric("Classe Pr√©dite", explanations['prediction']['predicted_class_name'])
                        
                        if not is_correct:
                            st.error("üîç **Erreur de classification d√©tect√©e !**")
                    
                    # Comparaison des modalit√©s
                    st.subheader("üîÑ Comparaison des Modalit√©s")
                    
                    ind_preds = explanations['individual_predictions']
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric(
                            "üìù Texte Seul", 
                            pipeline.category_names.get(ind_preds['text_prediction'], 'Unknown'),
                            f"Confiance: {ind_preds['text_confidence']:.3f}"
                        )
                    
                    with col2:
                        st.metric(
                            "üñºÔ∏è Image Seule", 
                            pipeline.category_names.get(ind_preds['image_prediction'], 'Unknown'),
                            f"Confiance: {ind_preds['image_confidence']:.3f}"
                        )
                    
                    # Importance des modalit√©s
                    st.subheader("‚öñÔ∏è Importance des Modalit√©s")
                    
                    modality_imp = explanations['modality_importance']
                    
                    importance_df = pd.DataFrame({
                        'Modalit√©': ['Texte', 'Image'],
                        'Poids': [modality_imp['text_weight']*100, modality_imp['image_weight']*100]
                    })
                    
                    fig = px.pie(importance_df, values='Poids', names='Modalit√©',
                                title=f"Contribution des Modalit√©s (Strat√©gie: {fusion_strategy})")
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Analyse d√©taill√©e
                    st.subheader("üîç Analyse D√©taill√©e")
                    
                    tabs = st.tabs(["üìù Analyse Texte", "üñºÔ∏è Analyse Image", "üîó Analyse Fusion"])
                    
                    with tabs[0]:
                        text_analysis = explanations['text_analysis']
                        st.write("**Statistiques du texte:**")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Longueur", text_analysis['text_length'])
                        with col2:
                            st.metric("Nombre de mots", text_analysis['word_count'])
                        with col3:
                            st.metric("Confiance", f"{text_analysis['text_confidence']:.3f}")
                        
                        st.write("**Premiers mots:**")
                        st.write(" ‚Ä¢ ".join(text_analysis['top_words']))
                    
                    with tabs[1]:
                        image_analysis = explanations['image_analysis']
                        if image_analysis['feature_importance_available']:
                            st.write("**Features les plus importantes (indices):**")
                            for i, feature_idx in enumerate(image_analysis['top_features'], 1):
                                st.write(f"{i}. Feature {feature_idx}")
                        else:
                            st.info("Importance des features non disponible pour ce mod√®le")
                    
                    with tabs[2]:
                        fusion_analysis = explanations['fusion_analysis']
                        st.write("**Analyse de la fusion:**")
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            agreement_status = "‚úÖ Oui" if fusion_analysis['agreement'] else "‚ùå Non"
                            st.metric("Accord Texte-Image", agreement_status)
                        
                        with col2:
                            boost_status = "‚úÖ Oui" if fusion_analysis['confidence_boost'] else "‚ùå Non"
                            st.metric("Fusion Am√©liore", boost_status)
                        
                        with col3:
                            dominant = "üìù Texte" if fusion_analysis['dominant_modality'] == 'text' else "üñºÔ∏è Image"
                            st.metric("Modalit√© Dominante", dominant)
                        
                        # Interpr√©tation
                        st.write("**Interpr√©tation:**")
                        if fusion_analysis['agreement']:
                            st.success("üéØ Les deux modalit√©s sont d'accord, la pr√©diction est fiable")
                        else:
                            st.warning("‚ö†Ô∏è D√©saccord entre modalit√©s, v√©rifier la pr√©diction")
                        
                        if fusion_analysis['confidence_boost']:
                            st.info("üìà La fusion am√©liore la confiance de la pr√©diction")
                        else:
                            st.info("üìä La fusion n'am√©liore pas la confiance")
                
        except Exception as e:
            st.error(f"‚ùå Erreur g√©n√©ration explications: {str(e)}")
            st.info("üí° V√©rifiez que tous les mod√®les sont correctement charg√©s.")
    
    # Aide
    if not test_examples and mode == "üé≤ Exemple test_split":
        st.warning("‚ö†Ô∏è Aucun exemple test_split disponible. Utilisez le mode 'Saisie manuelle'.")
    
    # Suggestions d'am√©lioration
    if len(test_examples) < 10:
        with st.expander("üí° Suggestions d'am√©lioration"):
            st.markdown("""
            **Probl√®me identifi√©**: Peu d'exemples test_split disponibles avec images.
            
            **Causes possibles**:
            - Images manquantes dans le dossier `data/images/image_train/`
            - Test split trop petit ou mal r√©parti
            - Probl√®mes de chemins vers les images
            
            **Solutions sugg√©r√©es**:
            1. V√©rifier l'int√©grit√© du dataset d'images
            2. Augmenter la taille du test_split (actuellement 20%)
            3. √âquilibrer la r√©partition des cat√©gories dans le split
            4. Utiliser des exemples synth√©tiques pour les cat√©gories sous-repr√©sent√©es
            """)
    
    # Statistiques sur les cat√©gories
    if test_examples:
        with st.expander("üìä Statistiques d√©taill√©es"):
            category_stats = {}
            for example in test_examples:
                cat = example['class_name']
                if cat not in category_stats:
                    category_stats[cat] = {
                        'count': 0, 
                        'emoji': example['class_emoji'],
                        'desc': example['class_desc']
                    }
                category_stats[cat]['count'] += 1
            
            st.write("**Distribution par cat√©gorie**:")
            for cat_name, stats in sorted(category_stats.items(), key=lambda x: x[1]['count'], reverse=True):
                st.write(f"{stats['emoji']} **{cat_name}**: {stats['count']} exemples - {stats['desc']}")
            
            # Recommandations
            under_represented = [cat for cat, stats in category_stats.items() if stats['count'] < 2]
            if under_represented:
                st.warning(f"‚ö†Ô∏è Cat√©gories sous-repr√©sent√©es ({len(under_represented)}): {', '.join(under_represented[:5])}{'...' if len(under_represented) > 5 else ''}")

# Footer
st.markdown("---")
st.markdown("üõçÔ∏è **Challenge Rakuten** - Classification Multimodale | D√©velopp√© avec Streamlit")