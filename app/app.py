import streamlit as st
import pandas as pd
import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
from PIL import Image
import os
import sys
import plotly.express as px
# import plotly.graph_objects as go
# from plotly.subplots import make_subplots
# from pathlib import Path

from utils_path import *
import main #(chargement des donn√©es)
from utils import safe_read_csv

# Constantes de chemins additionnelles
TRAIN_IMAGES_DIR = DATA_DIR / "images" / "image_train"
TEST_IMAGES_DIR = DATA_DIR / "images" / "image_test"
X_TRAIN_FILE = DATA_DIR / "X_train_update.csv"
Y_TRAIN_FILE = DATA_DIR / "Y_train_CVw08PX.csv"
TEST_FILE = DATA_DIR / "X_test_update.csv"

# Configuration de la page
st.set_page_config(
    page_title="Challenge Rakuten - Classification Multimodale",
    page_icon="üõçÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Cache pour le pipeline
@st.cache_resource
def load_pipeline():
    """Charge le pipeline et les mod√®les (mis en cache)"""
    
    try:
    #     # V√©rifier que les fichiers existent
    #     st.write(f"**config.yaml existe:** {'‚úÖ' if CONFIG_FILE.exists() else '‚ùå'}")
    #     st.write(f"**preprocess.py existe:** {'‚úÖ' if (APP_DIR / 'preprocess.py').exists() else '‚ùå'}")
                
        # Ajouter le r√©pertoire du script au PATH Python
        if str(APP_DIR) not in sys.path:
            sys.path.insert(0, str(APP_DIR))
        
        from preprocess import ProductClassificationPipeline, PipelineConfig
        
        if not CONFIG_FILE.exists():
            st.error(f"‚ùå config.yaml non trouv√© dans {APP_DIR}")
            return None
            
        config = PipelineConfig.from_yaml(str(CONFIG_FILE))
        pipeline = ProductClassificationPipeline(config)
        
        # Charger les donn√©es pr√©-trait√©es
        pipeline.prepare_data(force_preprocess_image=False, force_preprocess_text=False)
        
        # Charger les mod√®les pr√©-entra√Æn√©s
        models_loaded = []
        
        try:
            pipeline.load_model('xgboost')
            models_loaded.append("XGBoost")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è XGBoost non disponible: {e}")
        
        try:
            pipeline.load_model('neural_net')
            models_loaded.append("Neural Network")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Neural Net non disponible: {e}")
        
        try:
            pipeline.load_text_model('SVM')
            models_loaded.append("SVM Texte")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è SVM Texte non disponible: {e}")
        
        if not models_loaded:
            st.error("‚ùå Aucun mod√®le n'a pu √™tre charg√©. V√©rifiez que main.py a √©t√© ex√©cut√©.")
            return None
        
        return pipeline
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement du pipeline: {e}")
        st.info("üí° Assurez-vous d'avoir ex√©cut√© main.py pour g√©n√©rer les mod√®les et donn√©es.")
        return None

# Cache pour les donn√©es de r√©sultats
@st.cache_data
def load_results_data():
    """Charge les donn√©es de r√©sultats et rapports"""
    results = {}
    
    # R√©sultats de comparaison des mod√®les
    results_files = {
        'image_models': get_result_file('models_comparaison_results.csv'),
        'text_model': get_result_file('text_model_results.csv'),
        'multimodal': get_report_file('multimodal_comparison_results.csv')
    }
    
    for key, file_path in results_files.items():
        if file_path.exists:
            try:
                results[key] = safe_read_csv(str(file_path))
            except Exception as e:
                st.warning(f"Erreur lecture {file_path}: {e}")
    
    # Rapports d√©taill√©s
    rapport_files = {
        'rapport_xgboost': get_rapport_file('rapport_xgboost.csv'),
        'rapport_neural_net': get_rapport_file('rapport_neural_net.csv'),
        'rapport_text_SVM': get_rapport_file('rapport_text_SVM.csv'),
        'erreurs_xgboost': get_erreur_file('erreurs_xgboost.csv'),
        'erreurs_neural_net': get_erreur_file('erreurs_neural_net.csv'),
        'erreurs_text_SVM': get_erreur_file('erreurs_text_SVM.csv')
    }
    
    for key, file_path in rapport_files.items():
        if file_path.exists():
            try:
                results[key] = safe_read_csv(str(file_path))
            except Exception as e:
                st.warning(f"Erreur lecture {file_path}: {e}")
    
    return results

def check_columns_and_get_mapping(df, expected_columns, file_type="rapport"):
    """
    V√©rifie les colonnes disponibles et retourne un mapping avec cr√©ation de colonnes manquantes
    
    Args:
        df: DataFrame √† analyser
        expected_columns: Liste des colonnes attendues
        file_type: Type de fichier ("rapport" ou "erreurs")
    """
    available_columns = df.columns.tolist()
    column_mapping = {}
    
    # Mapping bas√© sur les vraies colonnes g√©n√©r√©es par main.py
    if file_type == "rapport":
        possible_mappings = {
            'true_class_name': ['true_class_name', 'true_category_name', 'true_label'],
            'predicted_class_name': ['predicted_class_name', 'predicted_category_name', 'predicted_label'],
            'correct': ['correct', 'is_correct'],
            'confidence': ['prediction_probability', 'confidence', 'prob_max', 'max_proba'],  # prediction_probability en premier
            'true_category': ['true_category', 'true_label'],
            'predicted_category': ['predicted_category', 'predicted_label']
        }
    else:  # file_type == "erreurs"
        possible_mappings = {
            'true_class_name': ['true_class_name', 'true_category_name', 'true_label'],
            'predicted_class_name': ['predicted_class_name', 'predicted_category_name', 'predicted_label'],
            'correct': ['correct', 'is_correct'],
            'confidence': ['prediction_probability', 'confidence', 'prob_max', 'max_proba'],  # prediction_probability en premier
            'true_category': ['true_category', 'true_label'],
            'predicted_category': ['predicted_category', 'predicted_label']
        }
    
    # Cr√©er une copie du DataFrame pour ajouter les colonnes manquantes
    df_processed = df.copy()
    
    # Mapping des codes vers les noms
    category_names = {
            10: "Livres occasion",
            40: "Jeux consoles neuf", 
            50: "Accessoires gaming",
            60: "Consoles de jeux",
            1140: "Objets pop culture",
            1160: "Cartes de jeux",
            1180: "Jeux de r√¥le et figurines",
            1280: "Jouets enfant",
            1300: "Mod√©lisme",
            1281: "Jeux enfant", 
            1301: "Lingerie enfant et jeu de bar",
            1302: "Jeux et accessoires de plein air",
            1320: "Pu√©riculture",
            1560: "Mobilier",
            1920: "Linge de maison",
            1940: "√âpicerie",
            2060: "D√©coration",
            2220: "Animalerie",
            2280: "Journaux et revues occasion",
            2403: "Lots livres et magazines",
            2462: "Console et Jeux vid√©os occasion",
            2522: "Fournitures papeterie",
            2582: "Mobilier et accessoires de jardin",
            2583: "Piscine et accessoires",
            2585: "Outillage de jardin",
            2705: "Livres neufs",
            2905: "Jeux PC en t√©l√©chargement"
    }
    
    # Mapping d√©taill√© avec descriptions et emoji
    def get_category_description(code):
        descriptions = {
            10: {"name": "Livres occasion", "emoji": "üìö", "desc": "Romans, BD, essais d'occasion"},
            40: {"name": "Jeux consoles neuf", "emoji": "üÜï", "desc": "Jeux neufs pour consoles"},
            50: {"name": "Accessoires gaming", "emoji": "üéß", "desc": "Casques, manettes, √©quipements gamer"},
            60: {"name": "Consoles de jeux", "emoji": "üéÆ", "desc": "PlayStation, Xbox, Nintendo et autres"},
            1300: {"name": "Mod√©lisme", "emoji": "‚úàÔ∏è", "desc": "Maquettes, trains miniatures, dioramas"},
            1140: {"name": "Objets pop culture", "emoji": "üßô‚Äç‚ôÇÔ∏è", "desc": "Figurines, goodies, objets collectors"},
            1160: {"name": "Cartes de jeux", "emoji": "üÉè", "desc": "Cartes Pok√©mon, Magic, Yu-Gi-Oh!"},
            1180: {"name": "Jeux de r√¥le et figurines", "emoji": "üêâ", "desc": "Warhammer, Donjons & Dragons, figurines"},
            1280: {"name": "Jouets enfant", "emoji": "üß∏", "desc": "Jouets pour tous √¢ges, √©ducatifs ou ludiques"},
            1320: {"name": "Pu√©riculture", "emoji": "üë∂", "desc": "Biberons, poussettes, produits b√©b√©"},
            1560: {"name": "Mobilier", "emoji": "ü™ë", "desc": "Meubles et accessoires pour toutes les pi√®ces de la maison"},
            1920: {"name": "Linge de maison", "emoji": "üõèÔ∏è", "desc": "Draps, serviettes, couvertures"},
            1940: {"name": "√âpicerie", "emoji": "üõí", "desc": "Produits alimentaires et boissons"},
            2060: {"name": "D√©coration", "emoji": "üñºÔ∏è", "desc": "Objets d√©co, cadres, bougies"},
            2220: {"name": "Animalerie", "emoji": "üêæ", "desc": "Accessoires pour chiens, chats et NAC"},
            2280: {"name": "Journaux et revues occasion", "emoji": "üì∞", "desc": "Magazines, journaux, revues d'occasion"},
            1281: {"name": "Jeux enfant", "emoji": "üß©", "desc": "Jeux d'√©veil, de construction ou de soci√©t√©"},
            1301: {"name": "Lingerie enfant et jeu de bar", "emoji": "üß¶", "desc": "Chaussettes ludiques pour enfants, billard babyfoot et flechettes"},
            1302: {"name": "Jeux et accessoires de plein air", "emoji": "üè∏", "desc": "Trottinettes, ballons, jeux d'ext√©rieur"},
            2403: {"name": "Lots livres et magazines", "emoji": "üì¶", "desc": "Packs de livres, collections de magazines"},
            2462: {"name": "Console et Jeux vid√©os occasion", "emoji": "üíø", "desc": "Jeux vid√©o d'occasion pour toutes consoles"},
            2522: {"name": "Fournitures papeterie", "emoji": "üñäÔ∏è", "desc": "Stylos, cahiers, articles scolaires"},
            2582: {"name": "Mobilier et accessoire de jardin", "emoji": "üå≥", "desc": "Tables, chaises, bancs d'ext√©rieur"},
            2583: {"name": "Piscine et accessoires", "emoji": "üèä", "desc": "Piscines gonflables, jeux d'eau"},
            2585: {"name": "Outillage de jardin", "emoji": "üõ†Ô∏è", "desc": "Outils, tondeuses, √©quipements jardin"},
            2705: {"name": "Livres neufs", "emoji": "üìñ", "desc": "Romans, essais, albums neufs"},
            2905: {"name": "Jeux PC en t√©l√©chargement", "emoji": "üñ•Ô∏è", "desc": "Jeux pour ordinateur, clefs num√©riques"}
        }

        
        return descriptions.get(code, {
            "name": f"Code_{code}", 
            "emoji": "‚ùì", 
            "desc": "Cat√©gorie non document√©e"
        })
    
    # Fonction pour am√©liorer la s√©lection d'exemples
    def get_diverse_examples():
        """S√©lectionne des exemples en s'assurant d'avoir une bonne diversit√© de cat√©gories"""
        try:
            # Charger les donn√©es
            X_train_df = safe_read_csv('../data/X_train_update.csv')
            Y_train_df = safe_read_csv('../data/Y_train_CVw08PX.csv')
            
            # R√©cup√©rer les indices du test_split
            if hasattr(pipeline, 'preprocessed_data') and 'test_split_indices' in pipeline.preprocessed_data:
                test_split_indices = pipeline.preprocessed_data['test_split_indices']
            else:
                n_total = len(X_train_df)
                test_split_indices = X_train_df.index[-int(0.2 * n_total):]
            
            # Grouper par cat√©gorie
            available_indices = [idx for idx in test_split_indices if idx in X_train_df.index and idx in Y_train_df.index]
            
            category_groups = {}
            for idx in available_indices:
                if idx in Y_train_df.index:
                    category = Y_train_df.loc[idx, 'prdtypecode']
                    if category not in category_groups:
                        category_groups[category] = []
                    category_groups[category].append(idx)
            
            # S√©lectionner 2-3 exemples par cat√©gorie disponible
            selected_examples = []
            
            for category, indices in category_groups.items():
                # V√©rifier que les images existent
                valid_indices = []
                for idx in indices[:10]:  # V√©rifier les 10 premiers
                    row = X_train_df.loc[idx]
                    image_file = f"image_{row['imageid']}_product_{row['productid']}.jpg"
                    image_path = os.path.join('../data/images/image_train', image_file)
                    if image_path.exists():
                        valid_indices.append(idx)
                
                # Prendre 2-3 exemples valides par cat√©gorie
                if len(valid_indices) > 0:
                    n_samples = min(3, len(valid_indices))
                    selected_indices = np.random.choice(valid_indices, size=n_samples, replace=False)
                    selected_examples.extend(selected_indices)
            
            # Cr√©er les exemples
            samples = []
            for idx in selected_examples:
                row = X_train_df.loc[idx]
                label = Y_train_df.loc[idx]
                
                designation = str(row.get('designation', '')).strip()
                description = str(row.get('description', '')).strip()
                text = f"{designation} {description}".strip()
                
                image_file = f"image_{row['imageid']}_product_{row['productid']}.jpg"
                image_path = os.path.join('../data/images/image_train', image_file)
                
                class_code = label['prdtypecode']
                category_info = get_category_description(class_code)
                
                if len(text) > 20:
                    samples.append({
                        'text': text,
                        'image_path': image_path,
                        'class_name': category_info['name'],
                        'class_code': class_code,
                        'class_emoji': category_info['emoji'],
                        'class_desc': category_info['desc'],
                        'imageid': row['imageid'],
                        'productid': row['productid'],
                        'index': idx,
                        'designation': designation,
                        'description': description
                    })
            
            return samples, category_groups
            
        except Exception as e:
            st.error(f"‚ùå Erreur s√©lection exemples diversifi√©s: {e}")
            return [], {}
    
    for expected_col in expected_columns:
        # Chercher la colonne existante
        found = False
        for possible_name in possible_mappings.get(expected_col, [expected_col]):
            if possible_name in available_columns:
                column_mapping[expected_col] = possible_name
                found = True
                break
        
        # Si pas trouv√©e, essayer de cr√©er la colonne
        if not found:
            if expected_col == 'correct' and 'true_category' in available_columns and 'predicted_category' in available_columns:
                # Cr√©er la colonne 'correct' en comparant true_category et predicted_category
                df_processed['correct'] = df_processed['true_category'] == df_processed['predicted_category']
                column_mapping['correct'] = 'correct'
                st.info("‚úÖ Colonne 'correct' cr√©√©e automatiquement")
                found = True
                
            elif expected_col == 'confidence':
                # V√©rifier d'abord si prediction_probability existe
                if 'prediction_probability' in available_columns:
                    column_mapping['confidence'] = 'prediction_probability'
                    found = True
                elif file_type == "erreurs":
                    # Pour les fichiers d'erreurs, la confidence peut ne pas exister
                    st.info("‚ÑπÔ∏è Colonne 'confidence' non disponible dans le fichier d'erreurs")
                    # Ne pas cr√©er de colonne par d√©faut, juste ignorer
                    found = False
                else:
                    # Pour les rapports, essayer autres noms
                    found = False
                
            elif expected_col == 'true_class_name':
                # Essayer de cr√©er √† partir de true_category_name ou true_category
                if 'true_category_name' in available_columns:
                    column_mapping['true_class_name'] = 'true_category_name'
                    found = True
                elif 'true_category' in available_columns:
                    df_processed['true_class_name'] = df_processed['true_category'].map(category_names)
                    column_mapping['true_class_name'] = 'true_class_name'
                    st.info("‚úÖ Colonne 'true_class_name' cr√©√©e √† partir de 'true_category'")
                    found = True
                    
            elif expected_col == 'predicted_class_name':
                # Essayer de cr√©er √† partir de predicted_category_name ou predicted_category
                if 'predicted_category_name' in available_columns:
                    column_mapping['predicted_class_name'] = 'predicted_category_name'
                    found = True
                elif 'predicted_category' in available_columns:
                    df_processed['predicted_class_name'] = df_processed['predicted_category'].map(category_names)
                    column_mapping['predicted_class_name'] = 'predicted_class_name'
                    st.info("‚úÖ Colonne 'predicted_class_name' cr√©√©e √† partir de 'predicted_category'")
                    found = True
        
        # Si toujours pas trouv√©e, warning seulement si c'est critique
        if not found and expected_col != 'confidence':
            st.warning(f"‚ö†Ô∏è Colonne '{expected_col}' non trouv√©e. Colonnes disponibles: {available_columns}")
    
    return column_mapping, df_processed

# Sidebar pour navigation
st.sidebar.title("üõçÔ∏è Navigation")
page = st.sidebar.selectbox(
    "Choisir une page",
    ["üè† Accueil", "üìä R√©sultats Globaux", "üñºÔ∏è Analyse Images", "üìù Analyse Texte", 
     "üîó Analyse Multimodale", "üß™ Test Nouvelles Donn√©es", "üéØ Explicabilit√©"]
)

# Charger le pipeline
pipeline = load_pipeline()
results_data = load_results_data()

# V√©rification que le pipeline est disponible
if pipeline is None:
    st.error("‚ùå Pipeline non disponible")
    st.info("üí° Veuillez ex√©cuter main.py pour g√©n√©rer les mod√®les et donn√©es avant d'utiliser cette application.")
    st.stop()  # Arr√™te l'ex√©cution de l'app

# ==================== PAGE ACCUEIL ====================
if page == "üè† Accueil":
    st.title("üõçÔ∏è Challenge Rakuten - Classification Multimodale")
    st.markdown("---")
    
    # Pr√©sentation du projet
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ## üéØ Objectif du Challenge
        
        Ce projet vise √† **classifier automatiquement les produits Rakuten** en utilisant :
        - üìù **Texte** (designation + description)
        - üñºÔ∏è **Images** des produits
        - üîó **Fusion multimodale** des deux approches
        
        ### üìä Donn√©es du Challenge
        """)
        
        # Statistiques g√©n√©rales
        stats_col1, stats_col2, stats_col3 = st.columns(3)
        with stats_col1:
            st.metric("üì¶ Produits Total", "84,916")
            st.metric("üèãÔ∏è Train Balanc√©", "54,000")
        with stats_col2:
            st.metric("üéØ Classes", "27")
            st.metric("üß™ Test Split", "16,984")
        with stats_col3:
            st.metric("üñºÔ∏è Images", "84,916")
            st.metric("üìù Textes", "84,916")
    
    with col2:
        st.markdown("""
        ### üèÜ Meilleurs R√©sultats
        """)
        
        # Afficher les meilleurs r√©sultats si disponibles
        if 'multimodal' in results_data and not results_data['multimodal'].empty:
            try:
                best_model = results_data['multimodal'].loc[results_data['multimodal']['weighted_f1'].idxmax()]
                st.success(f"ü•á **{best_model.name}**")
                st.metric("F1-Score", f"{best_model['weighted_f1']:.3f}")
                st.metric("Accuracy", f"{best_model['accuracy']:.3f}")
            except Exception as e:
                st.info("R√©sultats multimodaux en cours de traitement...")
        else:
            st.info("R√©sultats multimodaux en cours de traitement...")
    
    # Distribution des classes
    st.markdown("### üìä Distribution des Classes")
    
    # Donn√©es de distribution (bas√©es sur vos outputs)
    class_data = {
        'Classe': [1, 4, 5, 6, 13, 114, 116, 118, 128, 132, 156, 192, 194, 206, 222, 228, 1281, 1301, 1302, 2403, 2462, 2522, 2582, 2583, 2585, 2705, 2905],
        'Nom': ["Livres occasion","Jeux consoles neuf", "Accessoires gaming","Consoles de jeux","Mod√©lisme","Objets pop culture","Cartes de jeux","Jeux de r√¥le et figurines","Jouets enfant","Pu√©riculture","Mobilier","Linge de maison","√âpicerie","D√©coration","Animalerie","Journaux et revues occasion","Jeux enfant", "Lingerie enfant et jeu de bar","Jeux et accessoires de plein air","Lots livres et magazines","Console et Jeux vid√©os occasion","Fournitures papeterie","Mobilier et accessoires de jardin","Piscine et accessoires","Outillage de jardin","Livres neufs","Jeux PC en t√©l√©chargement"
],
        '√âchantillons': [3116, 2508, 1681, 832, 2671, 3953, 764, 4870, 2070, 5045, 807, 2491, 3241, 5073, 4303, 803, 4993, 824, 4760, 4774, 1421, 4989, 2589, 10209, 2496, 2761, 872],
        'Pourcentage': [3.67, 2.95, 1.98, 0.98, 3.15, 4.66, 0.90, 5.74, 2.44, 5.94, 0.95, 2.93, 3.82, 5.97, 5.07, 0.95, 5.88, 0.97, 5.61, 5.62, 1.67, 5.88, 3.05, 12.02, 2.94, 3.25, 1.03]
    }
    
    df_classes = pd.DataFrame(class_data)
    
    if st.button("üîç Debug des chemins"):
        debug_paths()
        
    # Graphique interactif
    fig = px.bar(df_classes, x='Nom', y='√âchantillons', 
                 title="Distribution des Classes (Donn√©es Originales)",
                 labels={'Nom': 'Cat√©gorie', '√âchantillons': 'Nombre d\'√©chantillons'})
    fig.update_xaxes(tickangle=45)
    st.plotly_chart(fig, use_container_width=True)

# ==================== PAGE R√âSULTATS GLOBAUX ====================
elif page == "üìä R√©sultats Globaux":
    st.title("üìä R√©sultats Globaux de Classification")
    st.markdown("---")
    
    # Comparaison des mod√®les
    if 'image_models' in results_data and 'text_model' in results_data:
        st.subheader("üèÜ Comparaison des Performances")
        
        # Pr√©parer les donn√©es pour la comparaison
        comparaison_data = []
        
        # Mod√®les image
        for model_name, row in results_data['image_models'].iterrows():
            comparaison_data.append({
                'Mod√®le': model_name,
                'Type': 'Image',
                'Accuracy': row['accuracy'],
                'F1-Score': row['weighted_f1'],
                'Pr√©cision': row.get('weighted_precision', 0),
                'Rappel': row.get('weighted_recall', 0)
            })
        
        # Mod√®le texte
        for model_name, row in results_data['text_model'].iterrows():
            comparaison_data.append({
                'Mod√®le': model_name,
                'Type': 'Texte',
                'Accuracy': row['accuracy'],
                'F1-Score': row['weighted_f1'],
                'Pr√©cision': row.get('weighted_precision', 0),
                'Rappel': row.get('weighted_recall', 0)
            })
        
        # Mod√®les multimodaux
        if 'multimodal' in results_data and not results_data['multimodal'].empty:
            for model_name, row in results_data['multimodal'].iterrows():
                model_type = 'Multimodal' if 'multimodal' in str(row.get('model_type', '')) else 'Fusion'
                comparaison_data.append({
                    'Mod√®le': model_name,
                    'Type': model_type,
                    'Accuracy': row['accuracy'],
                    'F1-Score': row['weighted_f1'],
                    'Pr√©cision': row.get('weighted_precision', 0),
                    'Rappel': row.get('weighted_recall', 0)
                })
        
        df_comparaison = pd.DataFrame(comparaison_data)
        
        if not df_comparaison.empty:
            # Graphique de comparaison
            fig = px.scatter(df_comparaison, x='Accuracy', y='F1-Score', 
                            color='Type', size='Pr√©cision',
                            hover_data=['Mod√®le', 'Rappel'],
                            title="Performance des Mod√®les (Accuracy vs F1-Score)")
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau r√©capitulatif
            st.subheader("üìã Tableau R√©capitulatif")
            df_display = df_comparaison.round(3)
            st.dataframe(df_display, use_container_width=True)
    
    # M√©triques par classe (si disponible)
    if 'rapport_xgboost' in results_data:
        st.subheader("üìä Performance par Classe")
        
        rapport = results_data['rapport_xgboost']
        
        # V√©rifier les colonnes disponibles
        column_mapping, rapport_processed = check_columns_and_get_mapping(rapport, ['true_class_name', 'correct', 'confidence'], "rapport")
        
        if 'true_class_name' in column_mapping and 'correct' in column_mapping:
            # Calculer les m√©triques par classe
            try:
                # Utiliser le DataFrame trait√©
                true_col = column_mapping['true_class_name']
                correct_col = column_mapping['correct']
                conf_col = column_mapping.get('confidence', correct_col)
                
                class_metrics = rapport_processed.groupby(true_col).agg({
                    correct_col: 'mean',
                    conf_col: 'mean'
                }).round(3)
                
                class_metrics.columns = ['Accuracy', 'Confiance Moyenne']
                
                # Trier par accuracy
                class_metrics = class_metrics.sort_values('Accuracy', ascending=False)
                
                st.dataframe(class_metrics, use_container_width=True)
            except Exception as e:
                st.error(f"Erreur calcul m√©triques par classe: {e}")
                st.info("Colonnes disponibles: " + str(rapport.columns.tolist()))

# ==================== PAGE ANALYSE IMAGES ====================
elif page == "üñºÔ∏è Analyse Images":
    st.title("üñºÔ∏è Analyse des Mod√®les Image")
    st.markdown("---")
    
    # S√©lection du mod√®le
    model_choice = st.selectbox("Choisir le mod√®le image", ["xgboost", "neural_net"])
    
    if f'rapport_{model_choice}' in results_data:
        rapport = results_data[f'rapport_{model_choice}']
        
        # V√©rifier les colonnes disponibles
        column_mapping, rapport_processed = check_columns_and_get_mapping(rapport, ['correct', 'confidence', 'true_class_name', 'predicted_class_name'], "rapport")
        
        if 'correct' in column_mapping and 'confidence' in column_mapping:
            # M√©triques globales
            st.subheader("üìä M√©triques Globales")
            col1, col2, col3, col4 = st.columns(4)
            
            correct_col = column_mapping['correct']
            conf_col = column_mapping['confidence']
            
            with col1:
                accuracy = rapport_processed[correct_col].mean()
                st.metric("Accuracy", f"{accuracy:.3f}")
            
            with col2:
                confidence = rapport_processed[conf_col].mean()
                st.metric("Confiance Moyenne", f"{confidence:.3f}")
            
            with col3:
                high_conf = (rapport_processed[conf_col] > 0.8).sum()
                st.metric("Haute Confiance (>0.8)", f"{high_conf}")
            
            with col4:
                low_conf = (rapport_processed[conf_col] < 0.5).sum()
                st.metric("Faible Confiance (<0.5)", f"{low_conf}")
            
            # Distribution des confiances
            st.subheader("üìà Distribution des Confiances")
            fig = px.histogram(rapport_processed, x=conf_col, nbins=50,
                              title="Distribution des Scores de Confiance")
            st.plotly_chart(fig, use_container_width=True)
            
            # Matrice de confusion (top 10 classes)
            if 'true_class_name' in column_mapping and 'predicted_class_name' in column_mapping:
                st.subheader("üéØ Matrice de Confusion (Top 10 Classes)")
                
                true_col = column_mapping['true_class_name']
                pred_col = column_mapping['predicted_class_name']
                
                # Prendre les 10 classes les plus fr√©quentes
                top_classes = rapport_processed[true_col].value_counts().head(10).index
                rapport_top = rapport_processed[rapport_processed[true_col].isin(top_classes)]
                
                if not rapport_top.empty:
                    confusion_matrix = pd.crosstab(rapport_top[true_col], 
                                                 rapport_top[pred_col])
                    
                    fig = px.imshow(confusion_matrix, text_auto=True,
                                   title="Matrice de Confusion (Top 10 Classes)")
                    st.plotly_chart(fig, use_container_width=True)
        
        # Analyse des erreurs
        if f'erreurs_{model_choice}' in results_data:
            st.subheader("‚ùå Analyse des Erreurs")
            erreurs = results_data[f'erreurs_{model_choice}']
            
            # V√©rifier les colonnes des erreurs
            error_column_mapping, erreurs_processed = check_columns_and_get_mapping(erreurs, ['true_class_name', 'predicted_class_name', 'confidence'], "erreurs")
            
            if 'true_class_name' in error_column_mapping:
                true_col = error_column_mapping['true_class_name']
                
                # Erreurs par classe
                erreurs_par_classe = erreurs_processed.groupby(true_col).size().sort_values(ascending=False)
                
                fig = px.bar(x=erreurs_par_classe.index[:15], y=erreurs_par_classe.values[:15],
                            title="Nombre d'Erreurs par Classe (Top 15)")
                st.plotly_chart(fig, use_container_width=True)
                
                # Exemples d'erreurs
                st.subheader("üîç Exemples d'Erreurs")
                sample_errors = erreurs_processed.sample(min(10, len(erreurs_processed)))
                
                for _, error in sample_errors.iterrows():
                    true_name = error.get(error_column_mapping.get('true_class_name', 'N/A'), 'N/A')
                    pred_name = error.get(error_column_mapping.get('predicted_class_name', 'N/A'), 'N/A')
                    
                    with st.expander(f"Erreur: {true_name} ‚Üí {pred_name}"):
                        # Afficher la confiance seulement si elle existe
                        if 'confidence' in error_column_mapping:
                            conf_val = error.get(error_column_mapping['confidence'], 'N/A')
                            st.write(f"**Probabilit√© de pr√©diction**: {conf_val}")
                        elif 'prediction_probability' in error.index:
                            conf_val = error.get('prediction_probability', 'N/A')
                            st.write(f"**Probabilit√© de pr√©diction**: {conf_val}")
                        else:
                            st.write("**Probabilit√© de pr√©diction**: Non disponible")
                        
                        if 'error_type' in error:
                            st.write(f"**Type d'erreur**: {error.get('error_type', 'N/A')}")
                        
                        # Afficher des infos additionnelles disponibles
                        if 'imageid' in error:
                            st.write(f"**ID Image**: {error.get('imageid', 'N/A')}")
                        if 'original_index' in error:
                            st.write(f"**Index Original**: {error.get('original_index', 'N/A')}")
    else:
        st.warning(f"Rapport pour {model_choice} non disponible. Ex√©cutez d'abord main.py pour g√©n√©rer les rapports.")

# ==================== PAGE ANALYSE TEXTE ====================
elif page == "üìù Analyse Texte":
    st.title("üìù Analyse du Mod√®le Texte (SVM)")
    st.markdown("---")
    
    if 'rapport_text_SVM' in results_data:
        rapport = results_data['rapport_text_SVM']
        
        # V√©rifier les colonnes disponibles
        column_mapping, rapport_processed = check_columns_and_get_mapping(rapport, ['correct', 'confidence', 'text_sample'], "rapport")
        
        if 'correct' in column_mapping and 'confidence' in column_mapping:
            correct_col = column_mapping['correct']
            conf_col = column_mapping['confidence']
            
            # M√©triques globales
            st.subheader("üìä M√©triques Globales")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                accuracy = rapport_processed[correct_col].mean()
                st.metric("Accuracy", f"{accuracy:.3f}")
            
            with col2:
                confidence = rapport_processed[conf_col].mean()
                st.metric("Confiance Moyenne", f"{confidence:.3f}")
            
            with col3:
                high_conf = (rapport_processed[conf_col] > 0.8).sum()
                st.metric("Haute Confiance", f"{high_conf}")
            
            with col4:
                low_conf = (rapport_processed[conf_col] < 0.5).sum()
                st.metric("Faible Confiance", f"{low_conf}")
            
            # Analyse des textes
            st.subheader("üìù Analyse des Textes")
            
            # Longueur des textes
            if 'text_sample' in column_mapping:
                text_col = column_mapping['text_sample']
                rapport_processed['text_length'] = rapport_processed[text_col].str.len()
                
                fig = px.histogram(rapport_processed, x='text_length', nbins=50,
                                  title="Distribution des Longueurs de Texte")
                st.plotly_chart(fig, use_container_width=True)
                
                # Corr√©lation longueur vs confiance
                fig = px.scatter(rapport_processed, x='text_length', y=conf_col,
                                color=correct_col, title="Longueur du Texte vs Confiance")
                st.plotly_chart(fig, use_container_width=True)
            
            # Mots les plus fr√©quents dans les erreurs
            if 'erreurs_text_SVM' in results_data:
                st.subheader("üîç Analyse des Erreurs Texte")
                erreurs = results_data['erreurs_text_SVM']
                
                # V√©rifier les colonnes des erreurs
                error_column_mapping, erreurs_processed = check_columns_and_get_mapping(erreurs, ['true_class_name', 'predicted_class_name', 'confidence', 'text_sample'], "erreurs")
                
                # Quelques exemples d'erreurs
                st.write("**Exemples d'erreurs de classification :**")
                sample_errors = erreurs_processed.sample(min(5, len(erreurs_processed)))
                
                for _, error in sample_errors.iterrows():
                    true_class = error.get(error_column_mapping.get('true_class_name', 'N/A'), 'N/A')
                    pred_class = error.get(error_column_mapping.get('predicted_class_name', 'N/A'), 'N/A')
                    
                    with st.expander(f"Erreur: {true_class} ‚Üí {pred_class}"):
                        # Afficher la confiance seulement si elle existe
                        if 'confidence' in error_column_mapping:
                            conf_val = error.get(error_column_mapping['confidence'], 'N/A')
                            st.write(f"**Confiance**: {conf_val}")
                        else:
                            st.write("**Confiance**: Non disponible")
                        
                        if 'text_sample' in error_column_mapping:
                            text_sample = error.get(error_column_mapping['text_sample'], 'N/A')
                            st.write(f"**Texte**: {str(text_sample)[:200]}...")
    else:
        st.warning("Rapport texte SVM non disponible. Ex√©cutez d'abord main.py pour g√©n√©rer les rapports.")

# ==================== PAGE ANALYSE MULTIMODALE ====================
elif page == "üîó Analyse Multimodale":
    st.title("üîó Analyse Multimodale")
    st.markdown("---")
    
    if 'multimodal' in results_data and not results_data['multimodal'].empty:
        multimodal_results = results_data['multimodal']
        
        # Comparaison des strat√©gies de fusion
        st.subheader("üîÄ Comparaison des Strat√©gies de Fusion")
        
        # Filtrer les r√©sultats multimodaux
        fusion_results = multimodal_results[multimodal_results['model_type'] == 'multimodal']
        
        if not fusion_results.empty:
            # Graphique de comparaison
            fig = px.bar(fusion_results, x=fusion_results.index, y='weighted_f1',
                        title="Performance des Strat√©gies de Fusion")
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau d√©taill√©
            st.dataframe(fusion_results[['accuracy', 'weighted_f1']].round(3), use_container_width=True)
        
        # Analyse de l'am√©lioration multimodale
        st.subheader("üìà Gain de la Fusion Multimodale")
        
        # Comparer avec les mod√®les individuels
        individual_results = multimodal_results[multimodal_results['model_type'] != 'multimodal']
        
        if not individual_results.empty:
            comparaison_fig = px.bar(
                x=multimodal_results.index,
                y=multimodal_results['weighted_f1'],
                color=multimodal_results['model_type'],
                title="Comparaison Individuel vs Multimodal"
            )
            st.plotly_chart(comparaison_fig, use_container_width=True)
    else:
        st.warning("R√©sultats multimodaux non disponibles. Ex√©cutez d'abord main.py pour g√©n√©rer les analyses multimodales.")

# ==================== PAGE TEST NOUVELLES DONN√âES ====================
elif page == "üß™ Test Nouvelles Donn√©es":
    st.title("üß™ Test sur Nouvelles Donn√©es")
    st.markdown("---")
    
    # Explication des modes
    with st.expander("üìñ Explication des modes de test"):
        st.markdown("""
        **üé≤ Exemple test_split**: Utilise des donn√©es **non vues pendant l'entra√Ænement** (20% des donn√©es d'origine). 
        Les labels sont connus, permettant une √©valuation correcte des performances.
        
        **üèÜ Exemple challenge**: Utilise les **vraies donn√©es de test du challenge**. 
        Les labels ne sont pas connus, simule une utilisation r√©elle.
        
        **‚úçÔ∏è Saisie manuelle**: Permet de tester avec vos propres donn√©es.
        
        **üìÅ Upload fichier**: Traite des fichiers CSV avec plusieurs exemples.
        """)
    
    st.markdown("---")
    
    # S√©lection des param√®tres
    st.subheader("‚öôÔ∏è Configuration")
    col1, col2 = st.columns(2)
    
    with col1:
        model_type = st.selectbox("Mod√®le Image", ["xgboost", "neural_net"])
    
    # Fonction pour extraire infos d'une image s√©lectionn√©e
    def extract_info_from_image(image_name):
        """Extrait les informations produit √† partir du nom d'image"""
        try:
            # Format: image_{imageid}_product_{productid}.jpg
            parts = image_name.replace('.jpg', '').replace('.jpeg', '').replace('.png', '')
            if 'image_' in parts and '_product_' in parts:
                imageid = parts.split('image_')[1].split('_product_')[0]
                productid = parts.split('_product_')[1]
                
                # Charger les donn√©es
                X_test_df = safe_read_csv(str(TEST_FILE))  
                
                # Chercher la ligne correspondante
                matching_row = X_test_df[
                    (X_test_df['imageid'].astype(str) == str(imageid)) & 
                    (X_test_df['productid'].astype(str) == str(productid))
                ]
                
                if not matching_row.empty:
                    row = matching_row.iloc[0]
                    text = f"{row.get('designation', '')} {row.get('description', '')}".strip()
                    return {
                        'text': text,
                        'imageid': imageid,
                        'productid': productid,
                        'designation': row.get('designation', ''),
                        'description': row.get('description', '')
                    }
            return None
        except Exception as e:
            st.error(f"Erreur extraction info image: {e}")
            return None

    with col2:
        fusion_strategy = st.selectbox("Strat√©gie de Fusion", 
                                      ["mean", "product", "weighted", "confidence_weighted"])
    
    # Interface de test
    st.subheader("üìù Saisie des Donn√©es")
    
    # Modes de test
    test_mode = st.radio("Mode de test", 
                        ["üé≤ Exemple test_split", "üèÜ Exemple challenge", "‚úçÔ∏è Saisie manuelle"])
    
    if test_mode == "üé≤ Exemple test_split":
        st.info("üìä **Donn√©es test_split** : √âchantillons non vus pendant l'entra√Ænement (labels connus)")
        
        # Bouton pour g√©n√©rer un nouvel exemple
        if st.button("üé≤ G√©n√©rer nouvel exemple test_split"):
            # Charger des exemples diversifi√©s comme dans la page explicabilit√©
            try:
                X_train_df = safe_read_csv(str(X_TRAIN_FILE))
                Y_train_df = safe_read_csv(str(Y_TRAIN_FILE))
                
                if hasattr(pipeline, 'preprocessed_data') and 'test_split_indices' in pipeline.preprocessed_data:
                    test_split_indices = pipeline.preprocessed_data['test_split_indices']
                else:
                    n_total = len(X_train_df)
                    test_split_indices = X_train_df.index[-int(0.2 * n_total):]
                
                available_indices = [idx for idx in test_split_indices if idx in X_train_df.index and idx in Y_train_df.index]
                sample_idx = np.random.choice(available_indices)
                
                row = X_train_df.loc[sample_idx]
                label = Y_train_df.loc[sample_idx]
                
                text = f"{row.get('designation', '')} {row.get('description', '')}".strip()
                image_file = f"image_{row['imageid']}_product_{row['productid']}.jpg"
                image_path = TRAIN_IMAGES_DIR / image_file
                
                if image_path.exists() and len(text) > 10:
                    st.session_state.test_example = {
                        'text': text,
                        'image_path': str(image_path),
                        'class_name': pipeline.category_names.get(label['prdtypecode'], 'Unknown'),
                        'class_code': label['prdtypecode'],
                        'imageid': row['imageid'],
                        'productid': row['productid'],
                        'mode': 'test_split'
                    }
                else:
                    st.error("Exemple non valide, r√©essayez")
                    
            except Exception as e:
                st.error(f"Erreur g√©n√©ration exemple: {e}")
        
        # Afficher l'exemple actuel
        if 'test_example' not in st.session_state:
            # Exemple par d√©faut
            st.session_state.test_example = {
                'text': "Console de jeu PlayStation 5 derni√®re g√©n√©ration avec √©cran OLED",
                'image_path': None,
                'class_name': 'Exemple',
                'mode': 'manual'
            }
        
        if st.session_state.test_example['mode'] == 'test_split':
            example = st.session_state.test_example
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Texte du produit:**")
                text_input = st.text_area("Description + D√©signation", 
                                         value=example['text'], height=120, key="text_test_split")
                st.success(f"**Classe r√©elle:** {example['class_name']} ({example['class_code']})")
            
            with col2:
                st.write("**Image du produit:**")
                if example['image_path'] and os.path.exists(example['image_path']):
                    image = Image.open(example['image_path'])
                    st.image(image, caption=f"Image ID: {example['imageid']}", use_container_width=True)
                    temp_image_path = example['image_path']
                else:
                    st.error("Image non trouv√©e")
                    temp_image_path = None
        else:
            text_input = st.text_input("Texte du produit", "Console de jeu PlayStation 5", key="text_default")
            temp_image_path = None
    
    elif test_mode == "üèÜ Exemple challenge":
        st.info("üèÜ **Donn√©es challenge** : Vraies donn√©es de test (labels inconnus)")
        
        if st.button("üèÜ G√©n√©rer exemple challenge"):
            try:
                X_test_df = safe_read_csv(str(TEST_FILE))
                sample_idx = np.random.choice(X_test_df.index)
                row = X_test_df.loc[sample_idx]
                
                text = f"{row.get('designation', '')} {row.get('description', '')}".strip()
                image_file = f"image_{row['imageid']}_product_{row['productid']}.jpg"
                image_path = TEST_IMAGES_DIR / image_file
                
                if image_path.exists() and len(text) > 10:
                    st.session_state.test_example = {
                        'text': text,
                        'image_path': str(image_path),
                        'imageid': row['imageid'],
                        'productid': row['productid'],
                        'mode': 'challenge'
                    }
                else:
                    st.error("Exemple non valide, r√©essayez")
            except Exception as e:
                st.error(f"Erreur g√©n√©ration exemple challenge: {e}")
        
        if 'test_example' in st.session_state and st.session_state.test_example['mode'] == 'challenge':
            example = st.session_state.test_example
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Texte du produit:**")
                text_input = st.text_area("Description + D√©signation", 
                                         value=example['text'], height=120, key="text_challenge")
            
            with col2:
                st.write("**Image du produit:**")
                if example['image_path'] and os.path.exists(example['image_path']):
                    image = Image.open(example['image_path'])
                    st.image(image, caption=f"Image ID: {example['imageid']}", use_container_width=True)
                    temp_image_path = example['image_path']
                else:
                    st.error("Image non trouv√©e")
                    temp_image_path = None
        else:
            text_input = st.text_input("Texte du produit", "Console de jeu PlayStation 5", key="text_challenge_default")
            temp_image_path = None
    
    else:  # Saisie manuelle
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Texte du produit:**")
            # Initialisation du texte par d√©faut
            default_text = "Smartphone Samsung Galaxy derni√®re g√©n√©ration avec √©cran OLED"
            
            # Si une image a √©t√© s√©lectionn√©e et qu'on a extrait le texte
            if 'extracted_text' in st.session_state:
                default_text = st.session_state.extracted_text
            
            text_input = st.text_area("Description + D√©signation", 
                                     value=default_text, height=120, key="text_manual")
        
        with col2:
            st.write("**Image du produit:**")
            
            # Indiquer le chemin par d√©faut
            st.info("üí° S√©lectionnez une image du dossier `image_test` pour d√©tecter automatiquement le texte")
            
            uploaded_file = st.file_uploader(
                "Choisir une image du dossier image_test...", 
                type=["jpg", "jpeg", "png"],
                help="Naviguez vers le dossier data/images/image_test pour s√©lectionner une image"
            )
            
            if uploaded_file is not None:
                image = Image.open(uploaded_file)
                st.image(image, caption="Image s√©lectionn√©e", use_container_width=True)
                
                # Sauvegarder temporairement
                temp_dir = APP_DIR / "temp_uploads"
                temp_dir.mkdir(exist_ok=True)
                temp_image_path = temp_dir / uploaded_file.name
                image.save(str(temp_image_path))
                
                # Essayer d'extraire les infos automatiquement
                extracted_info = extract_info_from_image(uploaded_file.name)
                if extracted_info:
                    st.success("‚úÖ Texte d√©tect√© automatiquement !")
                    st.session_state.extracted_text = extracted_info['text']
                    
                    with st.expander("üìã Infos extraites"):
                        st.write(f"**Image ID:** {extracted_info['imageid']}")
                        st.write(f"**Product ID:** {extracted_info['productid']}")
                        st.write(f"**D√©signation:** {extracted_info['designation']}")
                        st.write(f"**Description:** {extracted_info['description']}")
                    
                    # Rerun pour mettre √† jour le text_area
                    st.rerun()
                else:
                    st.warning("‚ö†Ô∏è Impossible d'extraire le texte automatiquement. V√©rifiez le format du nom de fichier.")
            else:
                temp_image_path = None

    # Bouton de pr√©diction
    if st.button("üîç Classifier le Produit", disabled=(temp_image_path is None)):
        try:
            with st.spinner("Classification en cours..."):
                # Charger le mod√®le s√©lectionn√©
                pipeline.load_model(model_type)
                
                # S'assurer que le texte est bien une cha√Æne de caract√®res
                text_input_clean = str(text_input).strip()
                
                # Effectuer la pr√©diction
                results = pipeline.predict_multimodal(text_input_clean, temp_image_path, fusion_strategy)
                
                # Afficher les r√©sultats
                st.success("‚úÖ Classification termin√©e!")
                
                # R√©sultat principal
                st.subheader("üéØ R√©sultat Principal")
                st.success(f"**Classe pr√©dite:** {results['predicted_class_name']}")
                st.info(f"**Code classe:** {results['predicted_class']}")
                
                # Afficher la classe r√©elle si c'est un exemple test_split
                if test_mode == "üé≤ Exemple test_split" and 'test_example' in st.session_state:
                    example = st.session_state.test_example
                    if example['mode'] == 'test_split':
                        is_correct = results['predicted_class'] == example['class_code']
                        if is_correct:
                            st.success(f"‚úÖ **Correct !** Classe r√©elle: {example['class_name']}")
                        else:
                            st.error(f"‚ùå **Erreur !** Classe r√©elle: {example['class_name']}")
                
                # Probabilit√©s top 5
                st.subheader("üìä Top 5 des Probabilit√©s")
                top_indices = np.argsort(results['probabilities'])[-5:][::-1]
                top_probs = results['probabilities'][top_indices]
                top_classes = [pipeline.category_names[pipeline.idx_to_category[idx]] for idx in top_indices]
                
                prob_df = pd.DataFrame({
                    "Classe": top_classes,
                    "Probabilit√©": top_probs
                })
                
                # Graphique des probabilit√©s
                fig = px.bar(prob_df, x="Probabilit√©", y="Classe", orientation='h',
                            title="Top 5 des Pr√©dictions")
                st.plotly_chart(fig, use_container_width=True)
                
                # Comparaison des modalit√©s
                st.subheader("üîÑ Comparaison par Modalit√©")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Texte seul", 
                             pipeline.category_names[results['text_prediction']])
                
                with col2:
                    st.metric("Image seule", 
                             pipeline.category_names[results['image_prediction']])
                
                with col3:
                    st.metric("Fusion", 
                             results['predicted_class_name'])
                
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la classification: {str(e)}")
            st.error("V√©rifiez que tous les mod√®les sont correctement charg√©s.")
            
            # Informations de d√©bogage
            with st.expander("üîç Informations de d√©bogage"):
                st.write(f"**Type de text_input:** {type(text_input)}")
                st.write(f"**Contenu de text_input:** {text_input}")
                st.write(f"**Chemin image:** {temp_image_path}")
                st.write(f"**Mod√®le s√©lectionn√©:** {model_type}")
                st.write(f"**Strat√©gie de fusion:** {fusion_strategy}")
                st.write(f"**Mode de test:** {test_mode}")

# ==================== PAGE EXPLICABILIT√â ====================
elif page == "üéØ Explicabilit√©":
    st.title("üéØ Explicabilit√© des Mod√®les")
    st.markdown("---")
    
    # Explication des deux types d'explicabilit√©
    with st.expander("üìñ Types d'explicabilit√© disponibles"):
        st.markdown("""
        **üìä SHAP XGBoost** : Explique comment le mod√®le XGBoost utilise les features ResNet50 (embeddings 2048D) pour classifier les images.
        
        **üîó Explicabilit√© Multimodale** : Compare et explique la fusion entre le mod√®le texte (SVM) et le mod√®le image (XGBoost/Neural Net).
        """)
    
    # Tabs pour s√©parer les deux types d'explicabilit√©
    tab1, tab2 = st.tabs(["üìä SHAP XGBoost (Features Images)", "üîó Explicabilit√© Multimodale (Fusion)"])
    
    # ==================== TAB 1: SHAP XGBOOST ====================
    with tab1:
        st.subheader("üìä Analyses SHAP - Mod√®le XGBoost sur Features ResNet50")
        st.info("üí° **SHAP explique comment XGBoost** utilise les 2048 features extraites par ResNet50 pour classifier les images")
        
        # V√©rifier l'existence des fichiers SHAP
        shap_reports_dir = DATA_DIR / "reports"
        shap_files = {
            "Bar Plot": shap_reports_dir / "shap_bar_plot.png",
            "Dot Plot": shap_reports_dir / "shap_dot_plot.png",
            "Waterfall Exemple 1": shap_reports_dir / "shap_waterfall_exemple_1.png",
            "Waterfall Exemple 2": shap_reports_dir / "shap_waterfall_exemple_2.png", 
            "Waterfall Exemple 3": shap_reports_dir / "shap_waterfall_exemple_3.png",
            "Force Plot Exemple 1": shap_reports_dir / "shap_force_exemple_1.png",
            "Force Plot Exemple 2": shap_reports_dir / "shap_force_exemple_2.png",
            "Force Plot Exemple 3": shap_reports_dir / "shap_force_exemple_3.png"
        }
        
        # Organiser les graphiques
        available_files = {name: path for name, path in shap_files.items() if path.exists()}
        
        if available_files:
            # S√©parer les graphiques agr√©g√©s des exemples individuels
            aggregate_plots = {k: v for k, v in available_files.items() if k in ["Bar Plot", "Dot Plot"]}
            individual_plots = {k: v for k, v in available_files.items() if k not in ["Bar Plot", "Dot Plot"]}
            
            # Sub-tabs pour organiser l'affichage SHAP
            shap_tab1, shap_tab2 = st.tabs(["üìà Graphiques Agr√©g√©s", "üîç Exemples Individuels"])
            
            with shap_tab1:
                st.info("üìà **Importance globale** : Quelles features ResNet50 XGBoost consid√®re comme les plus importantes")
                for name, path in aggregate_plots.items():
                    st.subheader(f"üìä {name}")
                    try:
                        image = Image.open(path)
                        st.image(image, caption=f"SHAP {name} - XGBoost sur features ResNet50", use_container_width=True)
                    except Exception as e:
                        st.error(f"Erreur chargement {name}: {e}")
            
            with shap_tab2:
                st.info("üîç **Explications individuelles** : Comment XGBoost prend sa d√©cision pour des images sp√©cifiques")
                # Grouper par type
                waterfall_plots = {k: v for k, v in individual_plots.items() if "Waterfall" in k}
                force_plots = {k: v for k, v in individual_plots.items() if "Force" in k}
                
                if waterfall_plots:
                    st.subheader("üåä Waterfall Plots (Contribution de chaque feature)")
                    cols = st.columns(min(3, len(waterfall_plots)))
                    for i, (name, path) in enumerate(waterfall_plots.items()):
                        with cols[i % 3]:
                            try:
                                image = Image.open(path)
                                st.image(image, caption=name, use_container_width=True)
                            except Exception as e:
                                st.error(f"Erreur {name}: {e}")
                
                if force_plots:
                    st.subheader("‚ö° Force Plots (Vue d'ensemble des contributions)") 
                    cols = st.columns(min(3, len(force_plots)))
                    for i, (name, path) in enumerate(force_plots.items()):
                        with cols[i % 3]:
                            try:
                                image = Image.open(path)
                                st.image(image, caption=name, use_container_width=True)
                            except Exception as e:
                                st.error(f"Erreur {name}: {e}")
        else:
            st.warning("‚ö†Ô∏è Aucune image SHAP trouv√©e. Ex√©cutez d'abord l'analyse SHAP dans main.py pour g√©n√©rer les graphiques.")
            st.info("üí° Les fichiers SHAP devraient se trouver dans le dossier `data/reports/`")
    
    # ==================== TAB 2: EXPLICABILIT√â MULTIMODALE ====================
    with tab2:
        st.subheader("üîó Explicabilit√© Multimodale - Fusion Texte + Image")
        st.info("üí° **Compare et explique** comment la fusion entre mod√®le texte (SVM) et mod√®le image (XGBoost/Neural Net) prend ses d√©cisions")
        
        # Fonction pour r√©cup√©rer des exemples test_split
        @st.cache_data
        def get_test_split_examples():
            """R√©cup√®re des exemples depuis les donn√©es test_split pour l'explicabilit√©"""
            try:
                # Charger les donn√©es originales
                X_train_df = safe_read_csv(str(X_TRAIN_FILE))
                Y_train_df = safe_read_csv(str(Y_TRAIN_FILE))
                
                # R√©cup√©rer les indices du test_split depuis le pipeline
                if hasattr(pipeline, 'preprocessed_data') and 'test_split_indices' in pipeline.preprocessed_data:
                    test_split_indices = pipeline.preprocessed_data['test_split_indices']
                else:
                    # Fallback
                    n_total = len(X_train_df)
                    test_split_indices = X_train_df.index[-int(0.2 * n_total):]
                    st.warning("‚ö†Ô∏è Indices test_split non trouv√©s, utilisation d'une approximation")
                
                # Prendre quelques exemples pour l'explicabilit√©
                available_indices = [idx for idx in test_split_indices if idx in X_train_df.index and idx in Y_train_df.index]
                sample_indices = np.random.choice(available_indices, size=min(10, len(available_indices)), replace=False)
                
                samples = []
                for idx in sample_indices:
                    row = X_train_df.loc[idx]
                    label = Y_train_df.loc[idx]
                    
                    # Construire le texte
                    text = f"{row.get('designation', '')} {row.get('description', '')}".strip()
                    
                    # Construire le chemin image
                    image_file = f"image_{row['imageid']}_product_{row['productid']}.jpg"
                    image_path = TRAIN_IMAGES_DIR / image_file
                    
                    # Nom de la classe
                    class_name = pipeline.category_names.get(label['prdtypecode'], 'Unknown')
                    
                    if image_path.exists() and len(text) > 10:
                        samples.append({
                            'text': text,
                            'image_path': image_path,
                            'class_name': class_name,
                            'class_code': label['prdtypecode'],
                            'imageid': row['imageid'],
                            'productid': row['productid'],
                            'index': idx
                        })
                
                return samples
                
            except Exception as e:
                st.error(f"‚ùå Erreur chargement exemples test_split: {e}")
                return []
        
        # Charger les exemples test_split
        test_examples = get_test_split_examples()
        
        # Interface pour charger un exemple
        st.subheader("üìù S√©lection de l'Exemple pour Fusion")
        
        # Choix du mode
        mode = st.radio("Source des donn√©es", 
                       ["üé≤ Exemple test_split", "‚úçÔ∏è Saisie manuelle"], key="fusion_mode")
        
        if mode == "üé≤ Exemple test_split" and test_examples:
            st.info("üìä **Utilisation des donn√©es test_split** (non vues pendant l'entra√Ænement)")
            
            # S√©lectionner un exemple
            if st.button("üé≤ G√©n√©rer un exemple test_split", key="fusion_generate"):
                st.session_state.current_explainer_example = np.random.choice(test_examples)
            
            # Afficher l'exemple actuel
            if 'current_explainer_example' not in st.session_state and test_examples:
                st.session_state.current_explainer_example = test_examples[0]
            
            if 'current_explainer_example' in st.session_state:
                example = st.session_state.current_explainer_example
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**Texte du produit:**")
                    text_input = st.text_area("Description + D√©signation", 
                                             value=example['text'][:400] + "..." if len(example['text']) > 400 else example['text'],
                                             height=120, key="fusion_text")
                    st.success(f"**Classe r√©elle:** {example['class_name']} ({example['class_code']})")
                
                with col2:
                    st.write("**Image du produit:**")
                    if os.path.exists(example['image_path']):
                        image = Image.open(example['image_path'])
                        st.image(image, caption=f"Image ID: {example['imageid']}", use_container_width=True)
                        temp_image_path = example['image_path']
                    else:
                        st.error("Image non trouv√©e")
                        temp_image_path = None
        
        else:  # Saisie manuelle
            col1, col2 = st.columns(2)
            
            with col1:
                text_input = st.text_area("Texte", "Console de jeu PlayStation 5 derni√®re g√©n√©ration", key="fusion_manual_text")
            
            with col2:
                uploaded_file = st.file_uploader("Image", type=["jpg", "jpeg", "png"], key="fusion_upload")
                
                if uploaded_file is not None:
                    image = Image.open(uploaded_file)
                    st.image(image, caption="Image pour analyse", use_container_width=True)
                    
                    temp_dir = "temp_uploads"
                    os.makedirs(temp_dir, exist_ok=True)
                    temp_image_path = os.path.join(temp_dir, uploaded_file.name)
                    image.save(temp_image_path)
                else:
                    temp_image_path = None
        
        fusion_strategy = st.selectbox("Strat√©gie de fusion", ["mean", "product", "weighted", "confidence_weighted"], key="fusion_strategy")
        
        if st.button("üîç G√©n√©rer les Explications Multimodales", disabled=(temp_image_path is None), key="generate_fusion_explanations"):
            try:
                with st.spinner("G√©n√©ration des explications multimodales..."):
                    # S'assurer que le texte est bien une cha√Æne de caract√®res
                    def clean_text_input(text_input):
                        if isinstance(text_input, np.ndarray):
                            if text_input.size == 1:
                                return str(text_input.item()).strip()
                            else:
                                return ' '.join([str(item) for item in text_input.flatten()]).strip()
                        elif text_input is None:
                            return ""
                        else:
                            return str(text_input).strip()
                    
                    text_input_clean = clean_text_input(text_input)
                    
                    if len(text_input_clean) == 0:
                        st.error("‚ùå Le texte d'entr√©e est vide apr√®s nettoyage")
                        st.stop()
                    
                    explanations = pipeline.get_model_explanations(text_input_clean, temp_image_path, fusion_strategy)
                    
                    if 'error' in explanations:
                        st.error(f"‚ùå Erreur: {explanations['error']}")
                    else:
                        # R√©sultat de la pr√©diction
                        st.subheader("üéØ R√©sultat de la Fusion")
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Classe Pr√©dite", explanations['prediction']['predicted_class_name'])
                        with col2:
                            st.metric("Confiance", f"{explanations['prediction']['confidence']:.3f}")
                        with col3:
                            st.metric("Code Classe", explanations['prediction']['predicted_class'])
                        
                        # Comparaison avec la v√©rit√© terrain pour test_split
                        if mode == "üé≤ Exemple test_split" and 'current_explainer_example' in st.session_state:
                            example = st.session_state.current_explainer_example
                            is_correct = explanations['prediction']['predicted_class'] == example['class_code']
                            
                            st.subheader("üéØ √âvaluation vs V√©rit√© Terrain")
                            eval_col1, eval_col2, eval_col3 = st.columns(3)
                            
                            with eval_col1:
                                status = "‚úÖ Correct" if is_correct else "‚ùå Incorrect"
                                st.metric("R√©sultat", status)
                            with eval_col2:
                                st.metric("Classe R√©elle", example['class_name'])
                            with eval_col3:
                                st.metric("Classe Pr√©dite", explanations['prediction']['predicted_class_name'])
                            
                            if not is_correct:
                                st.error("üîç **Erreur de classification d√©tect√©e !**")
                        
                        # Comparaison des modalit√©s
                        st.subheader("üîÑ Comparaison des Modalit√©s")
                        
                        ind_preds = explanations['individual_predictions']
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric(
                                "üìù Texte Seul (SVM)", 
                                pipeline.category_names.get(ind_preds['text_prediction'], 'Unknown'),
                                f"Confiance: {ind_preds['text_confidence']:.3f}"
                            )
                        
                        with col2:
                            st.metric(
                                "üñºÔ∏è Image Seule (XGBoost/Neural)", 
                                pipeline.category_names.get(ind_preds['image_prediction'], 'Unknown'),
                                f"Confiance: {ind_preds['image_confidence']:.3f}"
                            )
                        
                        # Importance des modalit√©s
                        st.subheader("‚öñÔ∏è Poids des Modalit√©s dans la Fusion")
                        
                        modality_imp = explanations['modality_importance']
                        
                        importance_df = pd.DataFrame({
                            'Modalit√©': ['Texte (SVM)', 'Image (XGBoost/Neural)'],
                            'Poids': [modality_imp['text_weight']*100, modality_imp['image_weight']*100]
                        })
                        
                        fig = px.pie(importance_df, values='Poids', names='Modalit√©',
                                    title=f"Contribution des Modalit√©s (Strat√©gie: {fusion_strategy})")
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Analyse d√©taill√©e
                        st.subheader("üîç Analyse D√©taill√©e de la Fusion")
                        
                        tabs = st.tabs(["üìù Analyse Texte", "üñºÔ∏è Analyse Image", "üîó Analyse Fusion"])
                        
                        with tabs[0]:
                            text_analysis = explanations['text_analysis']
                            st.write("**Statistiques du texte (analys√© par SVM):**")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Longueur", text_analysis['text_length'])
                            with col2:
                                st.metric("Nombre de mots", text_analysis['word_count'])
                            with col3:
                                st.metric("Confiance SVM", f"{text_analysis['text_confidence']:.3f}")
                            
                            st.write("**Premiers mots d√©tect√©s:**")
                            st.write(" ‚Ä¢ ".join(text_analysis['top_words']))
                        
                        with tabs[1]:
                            image_analysis = explanations['image_analysis']
                            st.write("**Analyse des features image (par XGBoost/Neural Net):**")
                            if image_analysis['feature_importance_available']:
                                st.write("**Features ResNet50 les plus importantes (indices):**")
                                for i, feature_idx in enumerate(image_analysis['top_features'], 1):
                                    st.write(f"{i}. Feature {feature_idx}")
                                st.info("üí° Ces indices correspondent aux neurones ResNet50 les plus influents")
                            else:
                                st.info("Importance des features non disponible pour ce mod√®le")
                        
                        with tabs[2]:
                            fusion_analysis = explanations['fusion_analysis']
                            st.write("**Analyse de la strat√©gie de fusion:**")
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                agreement_status = "‚úÖ Oui" if fusion_analysis['agreement'] else "‚ùå Non"
                                st.metric("Accord Texte-Image", agreement_status)
                            
                            with col2:
                                boost_status = "‚úÖ Oui" if fusion_analysis['confidence_boost'] else "‚ùå Non"
                                st.metric("Fusion Am√©liore", boost_status)
                            
                            with col3:
                                dominant = "üìù Texte" if fusion_analysis['dominant_modality'] == 'text' else "üñºÔ∏è Image"
                                st.metric("Modalit√© Dominante", dominant)
                            
                            # Interpr√©tation
                            st.write("**Interpr√©tation de la fusion:**")
                            if fusion_analysis['agreement']:
                                st.success("üéØ Les modalit√©s texte (SVM) et image (XGBoost/Neural) sont d'accord, la pr√©diction est fiable")
                            else:
                                st.warning("‚ö†Ô∏è D√©saccord entre les modalit√©s, v√©rifier la pr√©diction de fusion")
                            
                            if fusion_analysis['confidence_boost']:
                                st.info("üìà La fusion multimodale am√©liore la confiance par rapport aux pr√©dictions individuelles")
                            else:
                                st.info("üìä La fusion n'am√©liore pas la confiance, une modalit√© domine probablement")
                    
            except Exception as e:
                st.error(f"‚ùå Erreur g√©n√©ration explications multimodales: {str(e)}")
                st.info("üí° V√©rifiez que tous les mod√®les (texte SVM + image XGBoost/Neural Net) sont correctement charg√©s.")
        
        # Aide
        if not test_examples and mode == "üé≤ Exemple test_split":
            st.warning("‚ö†Ô∏è Aucun exemple test_split disponible. Utilisez le mode 'Saisie manuelle'.")
        
        # Statistiques sur les cat√©gories (si disponible)
        if test_examples:
            with st.expander("üìä Statistiques d√©taill√©es des exemples test_split"):
                category_stats = {}
                for example in test_examples:
                    cat = example['class_name']
                    if cat not in category_stats:
                        category_stats[cat] = {'count': 0}
                    category_stats[cat]['count'] += 1
                
                st.write("**Distribution par cat√©gorie dans les exemples:**")
                for cat_name, stats in sorted(category_stats.items(), key=lambda x: x[1]['count'], reverse=True):
                    st.write(f"‚Ä¢ **{cat_name}**: {stats['count']} exemples")
                
                # Recommandations
                under_represented = [cat for cat, stats in category_stats.items() if stats['count'] < 2]
                if under_represented:
                    st.warning(f"‚ö†Ô∏è Cat√©gories sous-repr√©sent√©es ({len(under_represented)}): {', '.join(under_represented[:5])}{'...' if len(under_represented) > 5 else ''}")

# Footer
st.markdown("---")
st.markdown("üõçÔ∏è **Challenge Rakuten** - Classification Multimodale | D√©velopp√© avec Streamlit")